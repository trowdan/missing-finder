{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4ntmbjhi4j",
   "metadata": {},
   "source": [
    "# Homeward: AI-Powered missing persons finder\n",
    "\n",
    "### ‚ö†Ô∏è !! Go to the linked GitHub project for the full demo !! ‚ö†Ô∏è\n",
    "\n",
    "This prototype showcases just an interactive demo of what the web application available on GitHub provides, please check the full project on the attached repository.\n",
    "The command for the provisioning and deprovisioning of GCP resources are taken from the `setup.sh` and `destry.sh` of the main repository, so you will read `gcloud`, `bq` and `gsutil` commands there and there (instead of the python counterpart) for this reason.\n",
    "\n",
    "### Lost in a sea of unstructured data\n",
    "\n",
    "Every year, thousands of people go missing, and law enforcement agencies face a daunting challenge: **analyzing vast amounts of unstructured surveillance data** spread across multiple formats, locations, and timeframes. Traditional approaches require manual review of countless hours of video footage, photographs, and witness reports - a time-consuming process that can mean the difference between life and death.\n",
    "\n",
    "### How BigQuery + Gemini can make the difference\n",
    "\n",
    "**Homeward** demonstrates how BigQuery's AI capabilities can transform this critical real-world problem by:\n",
    "\n",
    "üß† **AI-Powered Content Analysis**: Using Google's Gemini multimodal models to automatically analyze surveillance footage and identify potential matches against missing persons reports and sightings.\n",
    "\n",
    "üìä **Pattern Recognition at Scale**: Leveraging BigQuery's analytical power to find temporal and spatial patterns across data points.\n",
    "\n",
    "üîç **Semantic Search**: Enabling natural language queries against unstructured video content and image data, by leveraging embedding and Vector Search within BigQuery to search missing persons and sightings.\n",
    "\n",
    "### What you'll see in this notebook\n",
    "\n",
    "In this demo, we'll walk through:\n",
    "\n",
    "1. **Setting up the GCP resources** - Creating datasets, external tables, and AI connections\n",
    "2. **Missing persons case management** - Create and summarize (through Gemini) missing persons reports\n",
    "4. **Sighting report management** - Create and summarize (through Gemini) sightings\n",
    "4. **Semantic search** - Find missing persons reports starting from sightings and vice-versa through vector search in BigQuery.\n",
    "3. **AI-Powered Video Analysis** - Using Gemini to analyze surveillance footage to find potential matches with missing persons reports\n",
    "5. **Environment cleanup** - Destroy the GCP resources created for this demo\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7554dffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/danilotrombino/Documents/Dev/Google/BQ Hackathon/missing-finder/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import date, time\n",
    "from IPython.display import Video\n",
    "import os\n",
    "import subprocess\n",
    "import secrets\n",
    "import tempfile\n",
    "import uuid\n",
    "\n",
    "from google.cloud import bigquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1addced0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup GCP Project variables\n",
    "PROJECT_ID = \"hackaton-pre-submit\"\n",
    "LOCATION = \"us-central1\"\n",
    "CONNECTION_ID = \"homeward_gcp_connection\"\n",
    "DATASET_ID = \"homeward\"\n",
    "BUCKET_NAME_PREFIX = \"homeward_videos_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfe5c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "def run_command(cmd):\n",
    "    \"\"\"Run command and return success status\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(cmd, shell=True, check=True, capture_output=True, text=True)\n",
    "        print(f\"‚úÖ Success: {cmd}\")\n",
    "        if result.stdout.strip():\n",
    "            print(f\"   Output: {result.stdout.strip()}\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"‚ùå Failed: {cmd}\")\n",
    "        if e.stderr:\n",
    "            print(f\"   Error: {e.stderr.strip()}\")\n",
    "        return False\n",
    "\n",
    "def generate_bucket_name():\n",
    "    \"\"\"Generate a unique bucket name with random suffix\"\"\"\n",
    "    random_suffix = secrets.token_hex(4)\n",
    "    return f\"{BUCKET_NAME_PREFIX}{random_suffix}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ac663eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BQ Client\n",
    "client = bigquery.Client(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d458be6",
   "metadata": {},
   "source": [
    "# üîß GCP Environment Setup\n",
    "This section handles the initial setup of Google Cloud Platform resources required for the Homeward missing persons finder system. **Skip this section if you have already run the `setup.sh` available in the GitHub repository** \n",
    "\n",
    "‚úÖ **What this section does:**\n",
    "- Enablement of needed Google APIs\n",
    "- Creation of BigQuery dataset\n",
    "- Creation of Cloud Storage buckets for video recordings (used as source for the BQ's object table)\n",
    "- Creation of BigQuery connections for AI/ML model integration\n",
    "- IAM roles and permissions to BQ's service account\n",
    "- External table that allows to analyze Google Cloud objects through BigQuery + Gemini\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rx8zk1tngsc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Setting up GCP Project: hackaton-pre-submit\n",
      "üìç Region: us-central1\n",
      "üîó Connection: homeward_gcp_connection\n",
      "üìä Dataset: homeward\n",
      "ü™£ Bucket name prefix: homeward_videos_\n",
      "\n",
      "=== Setting Project Configuration ===\n",
      "‚úÖ Success: gcloud config set project hackaton-pre-submit\n",
      "\n",
      "=== Verifying Project Access ===\n",
      "‚úÖ Success: gcloud projects describe hackaton-pre-submit\n",
      "   Output: createTime: '2025-09-22T20:36:19.917464Z'\n",
      "lifecycleState: ACTIVE\n",
      "name: hackaton-pre-submit\n",
      "projectId: hackaton-pre-submit\n",
      "projectNumber: '785373786347'\n",
      "\n",
      "=== Enabling Required APIs ===\n",
      "‚úÖ Success: gcloud services enable aiplatform.googleapis.com --project=hackaton-pre-submit\n",
      "‚úÖ Success: gcloud services enable bigquery.googleapis.com --project=hackaton-pre-submit\n",
      "‚úÖ Success: gcloud services enable storage.googleapis.com --project=hackaton-pre-submit\n",
      "\n",
      "=== Creating Storage Bucket ===\n",
      "Generated new bucket name: homeward_videos_7fde5434\n",
      "‚úÖ Success: gsutil mb -p hackaton-pre-submit -c STANDARD -l us-central1 gs://homeward_videos_7fde5434\n",
      "‚úÖ Created new bucket: gs://homeward_videos_7fde5434\n",
      "‚úÖ Success: gsutil iam ch -d allUsers:objectViewer gs://homeward_videos_7fde5434\n",
      "‚úÖ Success: gsutil iam ch -d allAuthenticatedUsers:objectViewer gs://homeward_videos_7fde5434\n",
      "‚úÖ Bucket configured as private\n",
      "\n",
      "=== Creating BigQuery Connection ===\n",
      "‚úÖ Success: bq mk --connection --location=us-central1 --project_id=hackaton-pre-submit --connection_type=CLOUD_RESOURCE homeward_gcp_connection || true\n",
      "   Output: Connection 785373786347.us-central1.homeward_gcp_connection successfully created\n",
      "\n",
      "=== Creating BigQuery Dataset ===\n",
      "‚úÖ Success: bq mk --dataset --location=us-central1 --project_id=hackaton-pre-submit homeward || true\n",
      "   Output: Dataset 'hackaton-pre-submit:homeward' successfully created.\n",
      "\n",
      "=== Configuring IAM Permissions ===\n",
      "Getting BigQuery connection service account...\n",
      "Found service account: bqcx-785373786347-y2is@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "‚úÖ Success: gcloud storage buckets add-iam-policy-binding gs://homeward_videos_7fde5434 --member=serviceAccount:bqcx-785373786347-y2is@gcp-sa-bigquery-condel.iam.gserviceaccount.com --role=roles/storage.objectViewer\n",
      "   Output: bindings:\n",
      "- members:\n",
      "  - projectEditor:hackaton-pre-submit\n",
      "  - projectOwner:hackaton-pre-submit\n",
      "  role: roles/storage.legacyBucketOwner\n",
      "- members:\n",
      "  - projectViewer:hackaton-pre-submit\n",
      "  role: roles/storage.legacyBucketReader\n",
      "- members:\n",
      "  - serviceAccount:bqcx-785373786347-y2is@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/storage.objectViewer\n",
      "etag: CAI=\n",
      "kind: storage#policy\n",
      "resourceId: projects/_/buckets/homeward_videos_7fde5434\n",
      "version: 1\n",
      "‚úÖ Success: gcloud projects add-iam-policy-binding hackaton-pre-submit --member=serviceAccount:bqcx-785373786347-y2is@gcp-sa-bigquery-condel.iam.gserviceaccount.com --role=roles/aiplatform.user\n",
      "   Output: bindings:\n",
      "- members:\n",
      "  - serviceAccount:bqcx-785373786347-y2is@gcp-sa-bigquery-condel.iam.gserviceaccount.com\n",
      "  role: roles/aiplatform.user\n",
      "- members:\n",
      "  - user:danilotrombino@gmail.com\n",
      "  role: roles/owner\n",
      "etag: BwY_a4mpkYA=\n",
      "version: 1\n",
      "‚úÖ IAM permissions configured\n",
      "\n",
      "‚úÖ GCP Project setup completed!\n",
      "üîë Project ID: hackaton-pre-submit\n",
      "üìç Region: us-central1\n",
      "ü™£ Storage Bucket: gs://homeward_videos_7fde5434\n",
      "üîó BigQuery Connection: homeward_gcp_connection\n",
      "üìä Dataset: homeward\n"
     ]
    }
   ],
   "source": [
    "print(f\"üöÄ Setting up GCP Project: {PROJECT_ID}\")\n",
    "print(f\"üìç Region: {LOCATION}\")\n",
    "print(f\"üîó Connection: {CONNECTION_ID}\")\n",
    "print(f\"üìä Dataset: {DATASET_ID}\")\n",
    "print(f\"ü™£ Bucket name prefix: {BUCKET_NAME_PREFIX}\")\n",
    "\n",
    "\n",
    "# Execute setup commands\n",
    "print(\"\\n=== Setting Project Configuration ===\")\n",
    "run_command(f\"gcloud config set project {PROJECT_ID}\")\n",
    "\n",
    "print(\"\\n=== Verifying Project Access ===\")\n",
    "run_command(f\"gcloud projects describe {PROJECT_ID}\")\n",
    "\n",
    "print(\"\\n=== Enabling Required APIs ===\")\n",
    "required_apis = [\n",
    "    \"aiplatform.googleapis.com\",\n",
    "    \"bigquery.googleapis.com\", \n",
    "    \"storage.googleapis.com\"\n",
    "]\n",
    "\n",
    "for api in required_apis:\n",
    "    run_command(f\"gcloud services enable {api} --project={PROJECT_ID}\")\n",
    "\n",
    "print(\"\\n=== Creating Storage Bucket ===\")\n",
    "\n",
    "# Generate new bucket name if needed\n",
    "BUCKET_NAME = generate_bucket_name()\n",
    "print(f\"Generated new bucket name: {BUCKET_NAME}\")\n",
    "\n",
    "# Create the bucket\n",
    "if run_command(f\"gsutil mb -p {PROJECT_ID} -c STANDARD -l {LOCATION} gs://{BUCKET_NAME}\"):\n",
    "    print(f\"‚úÖ Created new bucket: gs://{BUCKET_NAME}\")\n",
    "    \n",
    "    # Set bucket to private\n",
    "    run_command(f\"gsutil iam ch -d allUsers:objectViewer gs://{BUCKET_NAME}\")\n",
    "    run_command(f\"gsutil iam ch -d allAuthenticatedUsers:objectViewer gs://{BUCKET_NAME}\")\n",
    "    print(\"‚úÖ Bucket configured as private\")\n",
    "\n",
    "\n",
    "print(\"\\n=== Creating BigQuery Connection ===\")\n",
    "run_command(f\"bq mk --connection --location={LOCATION} --project_id={PROJECT_ID} --connection_type=CLOUD_RESOURCE {CONNECTION_ID} || true\")\n",
    "\n",
    "print(\"\\n=== Creating BigQuery Dataset ===\")  \n",
    "run_command(f\"bq mk --dataset --location={LOCATION} --project_id={PROJECT_ID} {DATASET_ID} || true\")\n",
    "\n",
    "print(\"\\n=== Configuring IAM Permissions ===\")\n",
    "# Get BigQuery connection service account and grant bucket access\n",
    "print(\"Getting BigQuery connection service account...\")\n",
    "connection_full_id = f\"{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}\"\n",
    "get_sa_cmd = f'bq show --format json --connection {connection_full_id} | python3 -c \"import sys, json; data=json.load(sys.stdin); print(data[\\'cloudResource\\'][\\'serviceAccountId\\'])\"'\n",
    "\n",
    "try:\n",
    "    result = subprocess.run(get_sa_cmd, shell=True, check=True, capture_output=True, text=True)\n",
    "    service_account = result.stdout.strip()\n",
    "    if service_account:\n",
    "        print(f\"Found service account: {service_account}\")\n",
    "        \n",
    "        # Grant storage permissions\n",
    "        run_command(f\"gcloud storage buckets add-iam-policy-binding gs://{BUCKET_NAME} --member=serviceAccount:{service_account} --role=roles/storage.objectViewer\")\n",
    "        \n",
    "        # Grant Vertex AI permissions  \n",
    "        run_command(f\"gcloud projects add-iam-policy-binding {PROJECT_ID} --member=serviceAccount:{service_account} --role=roles/aiplatform.user\")\n",
    "        \n",
    "        print(\"‚úÖ IAM permissions configured\")\n",
    "    else:\n",
    "        print(\"‚ùå Could not retrieve service account\")\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"‚ùå Failed to configure IAM permissions - may need manual setup\")\n",
    "\n",
    "print(\"\\n‚úÖ GCP Project setup completed!\")\n",
    "print(f\"üîë Project ID: {PROJECT_ID}\")\n",
    "print(f\"üìç Region: {LOCATION}\")\n",
    "print(f\"ü™£ Storage Bucket: gs://{BUCKET_NAME}\")\n",
    "print(f\"üîó BigQuery Connection: {CONNECTION_ID}\")\n",
    "print(f\"üìä Dataset: {DATASET_ID}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba6a638c",
   "metadata": {},
   "source": [
    "# BigQuery DDLs Execution\n",
    "Run this section to create the basic tables needed for the first part of the demo (Video analysis will be performed at the end of the notebook).\n",
    "**Skip this section if you have already run the `setup.sh` available in the GitHub repository** \n",
    "\n",
    "‚úÖ **What this section does:**\n",
    "- Creation of missing persons table\n",
    "- Creation of sightings table\n",
    "- Creation of BQ ML model for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c51d7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_MISSING_PERSONS_TABLE_DDL = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{DATASET_ID}.missing_persons` (\n",
    "  /* Primary identifiers */\n",
    "  id STRING NOT NULL OPTIONS(description=\"Unique case identifier\"),\n",
    "  case_number STRING OPTIONS(description=\"Official case reference number if available\"),\n",
    "  \n",
    "  /* Personal Information */\n",
    "  name STRING NOT NULL OPTIONS(description=\"First name of the missing person\"),\n",
    "  surname STRING NOT NULL OPTIONS(description=\"Last name of the missing person\"),\n",
    "  date_of_birth DATE NOT NULL OPTIONS(description=\"Date of birth of the missing person\"),\n",
    "  gender STRING NOT NULL OPTIONS(description=\"Gender (Male/Female/Other/Prefer not to say)\"),\n",
    "  \n",
    "  /* Physical Description */\n",
    "  height FLOAT64 OPTIONS(description=\"Height in centimeters\"),\n",
    "  weight FLOAT64 OPTIONS(description=\"Weight in kilograms\"),\n",
    "  hair_color STRING OPTIONS(description=\"Hair color\"),\n",
    "  eye_color STRING OPTIONS(description=\"Eye color\"),\n",
    "  distinguishing_marks STRING OPTIONS(description=\"Scars, tattoos, birthmarks, unique features\"),\n",
    "  clothing_description STRING OPTIONS(description=\"Description of clothing and accessories when last seen\"),\n",
    "  \n",
    "  /* Last Seen Information */\n",
    "  last_seen_date DATE NOT NULL OPTIONS(description=\"Date when person was last seen\"),\n",
    "  last_seen_time TIME OPTIONS(description=\"Time when person was last seen\"),\n",
    "  last_seen_address STRING NOT NULL OPTIONS(description=\"Street address where person was last seen\"),\n",
    "  last_seen_city STRING NOT NULL OPTIONS(description=\"City where person was last seen\"),\n",
    "  last_seen_country STRING NOT NULL OPTIONS(description=\"Country where person was last seen\"),\n",
    "  last_seen_postal_code STRING OPTIONS(description=\"Postal code where person was last seen\"),\n",
    "  last_seen_latitude FLOAT64 OPTIONS(description=\"Latitude coordinates of last seen location\"),\n",
    "  last_seen_longitude FLOAT64 OPTIONS(description=\"Longitude coordinates of last seen location\"),\n",
    "  last_seen_geo GEOGRAPHY OPTIONS(description=\"SFS position of last seen location\"),\n",
    "\n",
    "  /* Case Details */\n",
    "  circumstances STRING NOT NULL OPTIONS(description=\"Detailed description of circumstances of disappearance\"),\n",
    "  priority STRING NOT NULL OPTIONS(description=\"Priority level (High/Medium/Low)\"),\n",
    "  status STRING NOT NULL OPTIONS(description=\"Case status (Active/Resolved/Suspended)\"),\n",
    "  description STRING OPTIONS(description=\"General case description\"),\n",
    "  \n",
    "  /* Additional Information */\n",
    "  medical_conditions STRING OPTIONS(description=\"Medical conditions or mental health information\"),\n",
    "  additional_info STRING OPTIONS(description=\"Any other relevant information\"),\n",
    "  \n",
    "  /* Media */\n",
    "  photo_url STRING OPTIONS(description=\"URL to photo of missing person\"),\n",
    "  \n",
    "  /* Contact Information (Reporter) */\n",
    "  reporter_name STRING NOT NULL OPTIONS(description=\"Name of person reporting the missing person\"),\n",
    "  reporter_phone STRING NOT NULL OPTIONS(description=\"Phone number of reporter\"),\n",
    "  reporter_email STRING OPTIONS(description=\"Email address of reporter\"),\n",
    "  relationship STRING NOT NULL OPTIONS(description=\"Relationship of reporter to missing person\"),\n",
    "  \n",
    "  /* Metadata */\n",
    "  created_date TIMESTAMP NOT NULL OPTIONS(description=\"Date and time when case was created\"),\n",
    "  updated_date TIMESTAMP NOT NULL OPTIONS(description=\"Date and time when case was last updated\"),\n",
    "  \n",
    "  /* AI-Generated Content */\n",
    "  ml_summary STRING OPTIONS(description=\"AI-generated comprehensive summary of the missing person case for analysis and matching\"),\n",
    "  ml_summary_embedding ARRAY<FLOAT64> OPTIONS(description=\"Embedding vector of the AI-generated summary for similarity search and matching\")\n",
    "\n",
    "  --TODO Add Missing Photo Embedding\n",
    ")\n",
    "PARTITION BY DATE(created_date)\n",
    "CLUSTER BY status, priority, last_seen_city\n",
    "OPTIONS(\n",
    "  description=\"Table storing comprehensive missing person case information for the Homeward application\",\n",
    "  labels=[(\"environment\", \"hackathon\"), (\"application\", \"{DATASET_ID}\"), (\"data_type\", \"missing_persons\")]\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb110654",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_SIGHTINGS_TABLE_DDL = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS `{DATASET_ID}.sightings` (\n",
    "  /* Primary identifiers */\n",
    "  id STRING NOT NULL OPTIONS(description=\"Unique sighting identifier\"),\n",
    "  sighting_number STRING OPTIONS(description=\"Official sighting reference number if available\"),\n",
    "  \n",
    "  /* Sighting Information */\n",
    "  sighted_date DATE NOT NULL OPTIONS(description=\"Date when person was sighted\"),\n",
    "  sighted_time TIME OPTIONS(description=\"Time when person was sighted\"),\n",
    "  sighted_address STRING NOT NULL OPTIONS(description=\"Street address where person was sighted\"),\n",
    "  sighted_city STRING NOT NULL OPTIONS(description=\"City where person was sighted\"),\n",
    "  sighted_country STRING NOT NULL OPTIONS(description=\"Country where person was sighted\"),\n",
    "  sighted_postal_code STRING OPTIONS(description=\"Postal code where person was sighted\"),\n",
    "  sighted_latitude FLOAT64 OPTIONS(description=\"Latitude coordinates of sighting location\"),\n",
    "  sighted_longitude FLOAT64 OPTIONS(description=\"Longitude coordinates of sighting location\"),\n",
    "  sighted_geo GEOGRAPHY OPTIONS(description=\"SFS position of sighting location\"),\n",
    "  \n",
    "  /* Person Description */\n",
    "  apparent_gender STRING OPTIONS(description=\"Apparent gender of sighted person\"),\n",
    "  apparent_age_range STRING OPTIONS(description=\"Estimated age range (e.g., '20-30', '40-50')\"),\n",
    "  height_estimate FLOAT64 OPTIONS(description=\"Estimated height in centimeters\"),\n",
    "  weight_estimate FLOAT64 OPTIONS(description=\"Estimated weight in kilograms\"),\n",
    "  hair_color STRING OPTIONS(description=\"Observed hair color\"),\n",
    "  eye_color STRING OPTIONS(description=\"Observed eye color\"),\n",
    "  clothing_description STRING OPTIONS(description=\"Description of clothing and accessories observed\"),\n",
    "  distinguishing_features STRING OPTIONS(description=\"Notable features, marks, or characteristics observed\"),\n",
    "  \n",
    "  /* Sighting Details */\n",
    "  description STRING NOT NULL OPTIONS(description=\"Detailed description of the sighting\"),\n",
    "  circumstances STRING OPTIONS(description=\"Circumstances under which person was sighted\"),\n",
    "  confidence_level STRING NOT NULL OPTIONS(description=\"Reporter's confidence level (High/Medium/Low)\"),\n",
    "  photo_url STRING OPTIONS(description=\"URL to photo of sighted person if available\"),\n",
    "  video_url STRING OPTIONS(description=\"URL to video footage if available\"),\n",
    "  \n",
    "  /* Source Information */\n",
    "  source_type STRING NOT NULL OPTIONS(description=\"Source of sighting (Witness/Manual_Entry/Other)\"),\n",
    "  witness_name STRING OPTIONS(description=\"Name of witness (if applicable)\"),\n",
    "  witness_phone STRING OPTIONS(description=\"Phone number of witness (if applicable)\"),\n",
    "  witness_email STRING OPTIONS(description=\"Email address of witness (if applicable)\"),\n",
    "  video_analytics_result_id STRING OPTIONS(description=\"Reference to video_analytics_results.id if converted from AI detection\"),\n",
    "  \n",
    "  /* Status and Processing */\n",
    "  status STRING NOT NULL OPTIONS(description=\"Sighting status (New/Under_Review/Verified/False_Positive/Archived)\"),\n",
    "  priority STRING NOT NULL OPTIONS(description=\"Priority level (High/Medium/Low)\"),\n",
    "  verified BOOLEAN NOT NULL OPTIONS(description=\"Whether sighting has been verified\"),\n",
    "  \n",
    "  /* Metadata */\n",
    "  created_date TIMESTAMP NOT NULL OPTIONS(description=\"Date and time when sighting was created\"),\n",
    "  updated_date TIMESTAMP NOT NULL OPTIONS(description=\"Date and time when sighting was last updated\"),\n",
    "  created_by STRING OPTIONS(description=\"User or system that created the sighting\"),\n",
    "  notes STRING OPTIONS(description=\"Additional notes or comments about the sighting\"),\n",
    "  \n",
    "  /* AI-Generated Content */\n",
    "  ml_summary STRING OPTIONS(description=\"AI-generated comprehensive summary of the sighting for analysis and matching\"),\n",
    "  ml_summary_embedding ARRAY<FLOAT64> OPTIONS(description=\"Embedding vector of the AI-generated summary for similarity search and matching\")\n",
    ")\n",
    "PARTITION BY DATE(created_date)\n",
    "CLUSTER BY status, priority, sighted_city, source_type\n",
    "OPTIONS(\n",
    "  description=\"Table storing sighting reports that can be linked to missing person cases\",\n",
    "  labels=[(\"environment\", \"hackathon\"), (\"application\", \"{DATASET_ID}\"), (\"data_type\", \"sightings\")]\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3fdf6bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CREATE_EMBEDDING_MODEL_DDL = f\"\"\"\n",
    "CREATE OR REPLACE MODEL `{DATASET_ID}.text_embedding_model`\n",
    "REMOTE WITH CONNECTION `{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}`\n",
    "OPTIONS (\n",
    "  endpoint = 'text-embedding-004'\n",
    ");\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "648u4jopupx",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Executing CREATE_MISSING_PERSONS_TABLE_DDL...\n",
      "‚úÖ CREATE_MISSING_PERSONS_TABLE_DDL executed successfully!\n",
      "üîß Query job completed: 33ed6dd6-1803-4fdf-9244-2bd9b701e951\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Executing CREATE_MISSING_PERSONS_TABLE_DDL...\")\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "query_job = client.query(CREATE_MISSING_PERSONS_TABLE_DDL, job_config=job_config)\n",
    "results = query_job.result()\n",
    "print(\"‚úÖ CREATE_MISSING_PERSONS_TABLE_DDL executed successfully!\")\n",
    "print(f\"üîß Query job completed: {query_job.job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "v2ie9c55wyq",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Executing CREATE_SIGHTINGS_TABLE_DDL...\n",
      "‚úÖ CREATE_SIGHTINGS_TABLE_DDL executed successfully!\n",
      "üîß Query job completed: 6320044b-ace3-4b87-b6f6-555de7fbce19\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Executing CREATE_SIGHTINGS_TABLE_DDL...\")\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "query_job = client.query(CREATE_SIGHTINGS_TABLE_DDL, job_config=job_config)\n",
    "results = query_job.result()\n",
    "print(\"‚úÖ CREATE_SIGHTINGS_TABLE_DDL executed successfully!\")\n",
    "print(f\"üîß Query job completed: {query_job.job_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "m9e258jo8uf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Executing CREATE_EMBEDDING_MODEL_DDL...\n",
      "‚úÖ CREATE_EMBEDDING_MODEL_DDL executed successfully!\n",
      "üîß Query job completed: b09e5837-936b-4859-a245-e3f471f0006f\n"
     ]
    }
   ],
   "source": [
    "print(\"üîß Executing CREATE_EMBEDDING_MODEL_DDL...\")\n",
    "job_config = bigquery.QueryJobConfig()\n",
    "query_job = client.query(CREATE_EMBEDDING_MODEL_DDL, job_config=job_config)\n",
    "# In case of error retry after some seconds, there could be a delay in IAM permissions propagation\n",
    "results = query_job.result()\n",
    "print(\"‚úÖ CREATE_EMBEDDING_MODEL_DDL executed successfully!\")\n",
    "print(f\"üîß Query job completed: {query_job.job_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8f61f70",
   "metadata": {},
   "source": [
    "# üé¨ Let's start with the demo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88f9c1",
   "metadata": {},
   "source": [
    "# üë§ Missing Person Case Management\n",
    "\n",
    "This section demonstrates how to register and manage missing person cases in.\n",
    "Each case includes information that can help law enforcement agencies track and coordinate search efforts.\n",
    "These includes:\n",
    "- Name and surname\n",
    "- Date of birth\n",
    "- Gender\n",
    "- Approximate Height\n",
    "- Approximate weight\n",
    "- Hair color\n",
    "- Eye color\n",
    "- Distinguishing marks\n",
    "- Clothing at the moment of the missing\n",
    "- Coordinates of last place the person has been seen\n",
    "- Medical conditions\n",
    "- Photo\n",
    "- Reporter information\n",
    "\n",
    "\n",
    "üéØ **Key capabilities:**\n",
    "- Create missing person profiles\n",
    "- Provide geo-points data types to enable BigQuery geo-queries\n",
    "- Store case summary in BigQuery through **Gemini integration**\n",
    "\n",
    "üìã **Use case:** \n",
    "Law enforcement agencies receive a missing person report and need to register it in the system for coordinated search efforts across multiple surveillance networks. Such reports are processed and summarized to enable NL-queries and semantic searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ab64689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sample case ID: e0ffda51-a883-44ee-9c20-5cbdb8064f2e\n",
      "üìã Sample case number: CASE-2025-0901-0001\n",
      "üë§ Sample person: John Doe\n"
     ]
    }
   ],
   "source": [
    "# Sample data for testing - this will be passed as parameters to the BQ Query. Note, the image comes from my sessioniza page :)\n",
    "sample_missing_person = {\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"case_number\": \"CASE-2025-0901-0001\",\n",
    "    \"name\": \"John\",\n",
    "    \"surname\": \"Doe\",\n",
    "    \"date_of_birth\": date(1990, 1, 15),\n",
    "    \"gender\": \"Male\",\n",
    "    \"height\": 175.0,\n",
    "    \"weight\": 70.0,\n",
    "    \"hair_color\": \"Brown\",\n",
    "    \"eye_color\": \"Green\",\n",
    "    \"distinguishing_marks\": \"Tattoo on right arm\",\n",
    "    \"clothing_description\": \"Black jacket, blue jeans, white sneakers\",\n",
    "    \"last_seen_date\": date(2025, 9, 1),\n",
    "    \"last_seen_time\": time(18, 45, 0),\n",
    "    \"last_seen_address\": \"456 Oak Avenue\",\n",
    "    \"last_seen_city\": \"San Francisco\",\n",
    "    \"last_seen_country\": \"USA\",\n",
    "    \"last_seen_postal_code\": \"94103\",\n",
    "    \"last_seen_latitude\": 37.7849,\n",
    "    \"last_seen_longitude\": -122.4094,\n",
    "    \"circumstances\": \"Failed to return home after evening jog\",\n",
    "    \"priority\": \"High\",\n",
    "    \"status\": \"Active\",\n",
    "    \"description\": \"Missing marathon runner\",\n",
    "    \"medical_conditions\": \"Diabetes - requires medication\",\n",
    "    \"additional_info\": \"Regular jogger, knows the area well\",\n",
    "    \"photo_url\": \"https://sessionize.com/image/1447-400o400o2-NWmSNCUaND99mbwapa6z6.jpg\",\n",
    "    \"reporter_name\": \"Jane Doe\",\n",
    "    \"reporter_phone\": \"4155559876\",\n",
    "    \"reporter_email\": \"jane.doe@email.com\",\n",
    "    \"relationship\": \"Wife\",\n",
    "}\n",
    "\n",
    "print(f\"üìã Sample case ID: {sample_missing_person['id']}\")\n",
    "print(f\"üìã Sample case number: {sample_missing_person['case_number']}\")\n",
    "print(\n",
    "    f\"üë§ Sample person: {sample_missing_person['name']} {sample_missing_person['surname']}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8v0xtjv9unp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Little hack to generate LLM summary on insert leveraging MERGE\n",
    "MISSING_PERSON_INSERT_QUERY = f\"\"\"\n",
    "MERGE `{DATASET_ID}.missing_persons` AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    @id AS id,\n",
    "    @case_number AS case_number,\n",
    "    @name AS name,\n",
    "    @surname AS surname,\n",
    "    @date_of_birth AS date_of_birth,\n",
    "    @gender AS gender,\n",
    "    @height AS height,\n",
    "    @weight AS weight,\n",
    "    @hair_color AS hair_color,\n",
    "    @eye_color AS eye_color,\n",
    "    @distinguishing_marks AS distinguishing_marks,\n",
    "    @clothing_description AS clothing_description,\n",
    "    @last_seen_date AS last_seen_date,\n",
    "    @last_seen_time AS last_seen_time,\n",
    "    @last_seen_address AS last_seen_address,\n",
    "    @last_seen_city AS last_seen_city,\n",
    "    @last_seen_country AS last_seen_country,\n",
    "    @last_seen_postal_code AS last_seen_postal_code,\n",
    "    @last_seen_latitude AS last_seen_latitude,\n",
    "    @last_seen_longitude AS last_seen_longitude,\n",
    "    CASE\n",
    "      WHEN @last_seen_latitude IS NOT NULL AND @last_seen_longitude IS NOT NULL\n",
    "      THEN ST_GEOGPOINT(@last_seen_longitude, @last_seen_latitude)\n",
    "      ELSE NULL\n",
    "    END AS last_seen_geo,\n",
    "    @circumstances AS circumstances,\n",
    "    @priority AS priority,\n",
    "    @status AS status,\n",
    "    @description AS description,\n",
    "    @medical_conditions AS medical_conditions,\n",
    "    @additional_info AS additional_info,\n",
    "    @photo_url AS photo_url,\n",
    "    @reporter_name AS reporter_name,\n",
    "    @reporter_phone AS reporter_phone,\n",
    "    @reporter_email AS reporter_email,\n",
    "    @relationship AS relationship,\n",
    "    CURRENT_TIMESTAMP() AS created_date,\n",
    "    CURRENT_TIMESTAMP() AS updated_date,\n",
    "    AI.GENERATE(\n",
    "      CONCAT(\n",
    "        'Generate a comprehensive summary paragraph for this missing person case for law enforcement analysis and matching purposes. ',\n",
    "        'Write it as a single, flowing, discursive paragraph without bullet points, lists, or structured formatting. ',\n",
    "        'Include key identifying features, circumstances, and critical search information in narrative form. ',\n",
    "        'Return only the summary paragraph without any introduction, conclusion, or additional commentary from the model. ',\n",
    "        'Person: ', @name, ' ', @surname, ', ',\n",
    "        'Age: ', CAST(DATE_DIFF(CURRENT_DATE(), @date_of_birth, YEAR) AS STRING), ' years old, ',\n",
    "        'Gender: ', @gender, ', ',\n",
    "        CASE\n",
    "          WHEN @height IS NOT NULL THEN CONCAT('Height: ', CAST(@height AS STRING), 'cm, ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @weight IS NOT NULL THEN CONCAT('Weight: ', CAST(@weight AS STRING), 'kg, ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @hair_color IS NOT NULL THEN CONCAT('Hair: ', @hair_color, ', ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @eye_color IS NOT NULL THEN CONCAT('Eyes: ', @eye_color, ', ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @distinguishing_marks IS NOT NULL THEN CONCAT('Distinguishing marks: ', @distinguishing_marks, '. ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @clothing_description IS NOT NULL THEN CONCAT('Last seen wearing: ', @clothing_description, '. ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        'Last seen on ', CAST(@last_seen_date AS STRING),\n",
    "        CASE\n",
    "          WHEN @last_seen_time IS NOT NULL THEN CONCAT(' at ', CAST(@last_seen_time AS STRING))\n",
    "          ELSE ''\n",
    "        END,\n",
    "        ' in ', @last_seen_city, ', ', @last_seen_country, '. ',\n",
    "        'Location: ', @last_seen_address,\n",
    "        CASE\n",
    "          WHEN @last_seen_postal_code IS NOT NULL THEN CONCAT(', ', @last_seen_postal_code)\n",
    "          ELSE ''\n",
    "        END,\n",
    "        '. Circumstances: ', @circumstances, '. ',\n",
    "        CASE\n",
    "          WHEN @medical_conditions IS NOT NULL THEN CONCAT('Medical conditions: ', @medical_conditions, '. ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        CASE\n",
    "          WHEN @additional_info IS NOT NULL THEN CONCAT('Additional information: ', @additional_info, '. ')\n",
    "          ELSE ''\n",
    "        END\n",
    "      ),\n",
    "      connection_id => '{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}',\n",
    "      endpoint => 'gemini-2.5-flash',\n",
    "      model_params => JSON '{{\"generation_config\": {{\"temperature\": 0}}}}'\n",
    "    ).result AS ml_summary\n",
    ") AS source\n",
    "ON target.id = source.id\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    id, case_number, name, surname, date_of_birth, gender,\n",
    "    height, weight, hair_color, eye_color, distinguishing_marks, clothing_description,\n",
    "    last_seen_date, last_seen_time, last_seen_address, last_seen_city, last_seen_country,\n",
    "    last_seen_postal_code, last_seen_latitude, last_seen_longitude, last_seen_geo,\n",
    "    circumstances, priority, status, description, medical_conditions, additional_info,\n",
    "    photo_url, reporter_name, reporter_phone, reporter_email, relationship,\n",
    "    created_date, updated_date, ml_summary\n",
    "  )\n",
    "  VALUES (\n",
    "    source.id, source.case_number, source.name, source.surname, source.date_of_birth, source.gender,\n",
    "    source.height, source.weight, source.hair_color, source.eye_color, source.distinguishing_marks, source.clothing_description,\n",
    "    source.last_seen_date, source.last_seen_time, source.last_seen_address, source.last_seen_city, source.last_seen_country,\n",
    "    source.last_seen_postal_code, source.last_seen_latitude, source.last_seen_longitude, source.last_seen_geo,\n",
    "    source.circumstances, source.priority, source.status, source.description, source.medical_conditions, source.additional_info,\n",
    "    source.photo_url, source.reporter_name, source.reporter_phone, source.reporter_email, source.relationship,\n",
    "    source.created_date, source.updated_date, source.ml_summary\n",
    "  );\n",
    "\"\"\"\n",
    "\n",
    "# Query to verify the record\n",
    "VERIFY_RECORD_QUERY = f\"\"\"\n",
    "SELECT\n",
    "    id,\n",
    "    case_number,\n",
    "    name,\n",
    "    surname,\n",
    "    date_of_birth,\n",
    "    gender,\n",
    "    height,\n",
    "    weight,\n",
    "    hair_color,\n",
    "    eye_color,\n",
    "    distinguishing_marks,\n",
    "    clothing_description,\n",
    "    last_seen_date,\n",
    "    last_seen_time,\n",
    "    last_seen_city,\n",
    "    circumstances,\n",
    "    priority,\n",
    "    status,\n",
    "    medical_conditions,\n",
    "    additional_info,\n",
    "    reporter_name,\n",
    "    relationship,\n",
    "    created_date,\n",
    "    ml_summary\n",
    "FROM `{DATASET_ID}.missing_persons`\n",
    "WHERE id = @case_id\n",
    "ORDER BY created_date DESC\n",
    "LIMIT 1;\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bcyy2a6lrq5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing parameterized missing person insert with ML summary generation...\n",
      "‚úÖ Missing person record inserted successfully, including AI-generated summary!\n",
      "üîë Case ID: e0ffda51-a883-44ee-9c20-5cbdb8064f2e\n",
      "üìã Case Number: CASE-2025-0901-0001\n",
      "üë§ Person: John Doe\n",
      "üîß Query job completed: 085b085f-6e33-4aa0-8f7c-5b578c40135e\n"
     ]
    }
   ],
   "source": [
    "# Execute the parameterized missing person insert query with ML summary generation\n",
    "\n",
    "try:\n",
    "    print(\"Executing parameterized missing person insert with ML summary generation...\")\n",
    "\n",
    "    # Configure the query job with parameters\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"id\", \"STRING\", sample_missing_person[\"id\"]),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"case_number\", \"STRING\", sample_missing_person[\"case_number\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"name\", \"STRING\", sample_missing_person[\"name\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"surname\", \"STRING\", sample_missing_person[\"surname\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"date_of_birth\", \"DATE\", sample_missing_person[\"date_of_birth\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"gender\", \"STRING\", sample_missing_person[\"gender\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"height\", \"FLOAT64\", sample_missing_person[\"height\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"weight\", \"FLOAT64\", sample_missing_person[\"weight\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"hair_color\", \"STRING\", sample_missing_person[\"hair_color\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"eye_color\", \"STRING\", sample_missing_person[\"eye_color\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"distinguishing_marks\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"distinguishing_marks\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"clothing_description\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"clothing_description\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_date\", \"DATE\", sample_missing_person[\"last_seen_date\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_time\", \"TIME\", sample_missing_person[\"last_seen_time\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_address\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"last_seen_address\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_city\", \"STRING\", sample_missing_person[\"last_seen_city\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_country\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"last_seen_country\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_postal_code\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"last_seen_postal_code\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_latitude\",\n",
    "                \"FLOAT64\",\n",
    "                sample_missing_person[\"last_seen_latitude\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_longitude\",\n",
    "                \"FLOAT64\",\n",
    "                sample_missing_person[\"last_seen_longitude\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"circumstances\", \"STRING\", sample_missing_person[\"circumstances\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"priority\", \"STRING\", sample_missing_person[\"priority\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"status\", \"STRING\", sample_missing_person[\"status\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"description\", \"STRING\", sample_missing_person[\"description\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"medical_conditions\",\n",
    "                \"STRING\",\n",
    "                sample_missing_person[\"medical_conditions\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"additional_info\", \"STRING\", sample_missing_person[\"additional_info\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"photo_url\", \"STRING\", sample_missing_person[\"photo_url\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"reporter_name\", \"STRING\", sample_missing_person[\"reporter_name\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"reporter_phone\", \"STRING\", sample_missing_person[\"reporter_name\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"reporter_email\", \"STRING\", sample_missing_person[\"reporter_email\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"relationship\", \"STRING\", sample_missing_person[\"relationship\"]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Execute the parameterized query\n",
    "    query_job = client.query(MISSING_PERSON_INSERT_QUERY, job_config=job_config)\n",
    "    results = query_job.result()  # Wait for the query to complete\n",
    "\n",
    "    print(\"‚úÖ Missing person record inserted successfully, including AI-generated summary!\")\n",
    "    print(f\"üîë Case ID: {sample_missing_person['id']}\")\n",
    "    print(f\"üìã Case Number: {sample_missing_person['case_number']}\")\n",
    "    print(\n",
    "        f\"üë§ Person: {sample_missing_person['name']} {sample_missing_person['surname']}\"\n",
    "    )\n",
    "    print(f\"üîß Query job completed: {query_job.job_id}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing parameterized insert query: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "\n",
    "    # Print more detailed error information if available\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")\n",
    "    if hasattr(e, \"message\"):\n",
    "        print(f\"Error message: {e.message}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "yjo4wa690y",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Querying the inserted record to view AI-generated summary...\n",
      "‚úÖ Verification query executed successfully!\n",
      "Total rows returned: 1\n",
      "\n",
      "================================================================================\n",
      "INSERTED MISSING PERSON RECORD WITH AI-GENERATED SUMMARY\n",
      "================================================================================\n",
      "üìã Case ID: e0ffda51-a883-44ee-9c20-5cbdb8064f2e\n",
      "üìã Case Number: CASE-2025-0901-0001\n",
      "üë§ Name: John Doe\n",
      "üéÇ Date of Birth: 1990-01-15\n",
      "‚öß Gender: Male\n",
      "üìè Physical: 175.0cm, 70.0kg\n",
      "üëÅÔ∏è Features: Brown hair, Green eyes\n",
      "üîç Distinguishing Marks: Tattoo on right arm\n",
      "üëï Clothing: Black jacket, blue jeans, white sneakers\n",
      "üìç Last Seen: 2025-09-01 at 18:45:00 in San Francisco\n",
      "‚ö†Ô∏è Circumstances: Failed to return home after evening jog\n",
      "üè• Medical Conditions: Diabetes - requires medication\n",
      "‚ÑπÔ∏è Additional Info: Regular jogger, knows the area well\n",
      "üìû Reporter: Jane Doe (Wife)\n",
      "üî¥ Priority: High\n",
      "üìä Status: Active\n",
      "üìÖ Created: 2025-09-22 22:45:23.785951+00:00\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ü§ñ AI-GENERATED SUMMARY:\n",
      "--------------------------------------------------------------------------------\n",
      "John Doe, a 35-year-old male, was last seen on September 1, 2025, at approximately 18:45:00 in San Francisco, USA, specifically at 456 Oak Avenue, 94103, failing to return home after his regular evening jog. He is described as 175cm tall and weighing 70kg, with brown hair and green eyes, and has a distinctive tattoo on his right arm. At the time of his disappearance, Doe was wearing a black jacket, blue jeans, and white sneakers. Of critical concern is his medical condition of diabetes, which necessitates regular medication, and while he is a regular jogger who knows the area well, his unexpected absence is highly unusual.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Summary Statistics:\n",
      "   ‚Ä¢ Length: 630 characters\n",
      "   ‚Ä¢ Word count: 106 words\n",
      "   ‚Ä¢ Format: Discursive paragraph\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"Querying the inserted record to view AI-generated summary...\")\n",
    "    job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[bigquery.ScalarQueryParameter(\"case_id\", \"STRING\", sample_missing_person[\"id\"])]\n",
    "    )\n",
    "\n",
    "    # Execute the verification query\n",
    "    query_job = client.query(VERIFY_RECORD_QUERY, job_config=job_config)\n",
    "    results = query_job.result()\n",
    "\n",
    "    print(\"‚úÖ Verification query executed successfully!\")\n",
    "    print(f\"Total rows returned: {results.total_rows}\")\n",
    "\n",
    "    if results.total_rows > 0:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INSERTED MISSING PERSON RECORD WITH AI-GENERATED SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for row in results:\n",
    "            print(f\"üìã Case ID: {row.id}\")\n",
    "            print(f\"üìã Case Number: {row.case_number}\")\n",
    "            print(f\"üë§ Name: {row.name} {row.surname}\")\n",
    "            print(f\"üéÇ Date of Birth: {row.date_of_birth}\")\n",
    "            print(f\"‚öß Gender: {row.gender}\")\n",
    "            print(f\"üìè Physical: {row.height}cm, {row.weight}kg\")\n",
    "            print(f\"üëÅÔ∏è Features: {row.hair_color} hair, {row.eye_color} eyes\")\n",
    "            print(f\"üîç Distinguishing Marks: {row.distinguishing_marks}\")\n",
    "            print(f\"üëï Clothing: {row.clothing_description}\")\n",
    "            print(\n",
    "                f\"üìç Last Seen: {row.last_seen_date} at {row.last_seen_time} in {row.last_seen_city}\"\n",
    "            )\n",
    "            print(f\"‚ö†Ô∏è Circumstances: {row.circumstances}\")\n",
    "            print(f\"üè• Medical Conditions: {row.medical_conditions}\")\n",
    "            print(f\"‚ÑπÔ∏è Additional Info: {row.additional_info}\")\n",
    "            print(f\"üìû Reporter: {row.reporter_name} ({row.relationship})\")\n",
    "            print(f\"üî¥ Priority: {row.priority}\")\n",
    "            print(f\"üìä Status: {row.status}\")\n",
    "            print(f\"üìÖ Created: {row.created_date}\")\n",
    "\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            print(\"ü§ñ AI-GENERATED SUMMARY:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{row.ml_summary}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "            # Calculate summary statistics\n",
    "            summary_length = len(row.ml_summary) if row.ml_summary else 0\n",
    "            word_count = len(row.ml_summary.split()) if row.ml_summary else 0\n",
    "            print(\"\\nüìä Summary Statistics:\")\n",
    "            print(f\"   ‚Ä¢ Length: {summary_length} characters\")\n",
    "            print(f\"   ‚Ä¢ Word count: {word_count} words\")\n",
    "            print(\n",
    "                f\"   ‚Ä¢ Format: {'Discursive paragraph' if summary_length > 100 else 'Short summary'}\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No records found with case ID '{sample_missing_person['id']}'\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error querying inserted record: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "\n",
    "    # Print more detailed error information if available\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc6d35f",
   "metadata": {},
   "source": [
    "# üëÅÔ∏è Sighting Reports Management\n",
    "\n",
    "This section handles the registration and management of potential sightings related to missing person cases. Sightings can come from various sources including manual reports or witness accounts.\n",
    "Sighting information includes:\n",
    "- Sighting description\n",
    "- Sighting date\n",
    "- Sighted time\n",
    "- Sighted alocation\n",
    "- Apparent gender\n",
    "- Age range\n",
    "- Estimate height\n",
    "- Distinguish features\n",
    "- Clothing description\n",
    "- Witness information\n",
    "\n",
    "üîç **Core functionality:**\n",
    "- Register sightings with location and timestamp data\n",
    "- Store case summary in BigQuery through **Gemini integration**\n",
    "\n",
    "üí° **Use Case:** When a witness reports seeing someone matching a missing person's description, or when AI analysis identifies a potential match in surveillance footage, this system captures and organizes that critical information for investigators.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18cc0f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sighting ID: 5945a5b3-9063-46b8-b5e8-63213571a028\n",
      "üìã Sighting Number: SIGHT-2024-070\n",
      "üëÅÔ∏è Person Description: 30 to 35-year-old male jogger, tall, near 70kg, brown hair, green eyes, wearing black jacket, blue j...\n",
      "üìç Location: Golden Gate Park, near the jogging trail, San Francisco\n",
      "üìÖ Sighting Date: 2024-08-21 at 08:30:00\n",
      "üìû Witness: Maria Rodriguez\n",
      "‚≠ê Confidence Level: High\n",
      "üö® Source Type: Witness\n",
      "üî¥ Priority: High\n",
      "‚úÖ Verified: False\n"
     ]
    }
   ],
   "source": [
    "# Sample sighting data that perfectly matches our missing person John Doe\n",
    "sample_sighting = {\n",
    "    \"id\": str(uuid.uuid4()),\n",
    "    \"sighting_number\": \"SIGHT-2024-070\",\n",
    "    \"description\": \"30 to 35-year-old male jogger, tall, near 70kg, brown hair, green eyes, wearing black jacket, blue jeans, white sneakers, has distinctive tattoo on right arm, appeared disoriented, matches missing diabetic runner from San Francisco\",\n",
    "    \"sighted_date\": date(2024, 8, 21),  # Day after John went missing\n",
    "    \"sighted_time\": time(8, 30, 0),\n",
    "    \"sighted_address\": \"Golden Gate Park, near the jogging trail\",\n",
    "    \"sighted_city\": \"San Francisco\",\n",
    "    \"sighted_country\": \"USA\",\n",
    "    \"sighted_postal_code\": \"94117\",\n",
    "    \"sighted_latitude\": 37.7694,\n",
    "    \"sighted_longitude\": -122.4862,\n",
    "    \"apparent_gender\": \"Male\",\n",
    "    \"apparent_age_range\": \"30-40\",\n",
    "    \"height_estimate\": 175.0,\n",
    "    \"hair_color\": \"Brown\",\n",
    "    \"clothing_description\": \"Black jacket, blue jeans, white sneakers\",\n",
    "    \"distinguishing_features\": \"Tattoo on right arm\",\n",
    "    \"source_type\": \"Witness\",\n",
    "    \"witness_name\": \"Maria Rodriguez\",\n",
    "    \"witness_phone\": \"4155551234\",\n",
    "    \"witness_email\": \"maria.rodriguez@email.com\",\n",
    "    \"circumstances\": \"Male marathon runner sitting on bench looking disoriented and in medical distress, appeared to be diabetic episode, matches description of missing person John Doe who requires diabetes medication, was wearing identical clothing to missing person report\",\n",
    "    \"confidence_level\": \"High\",\n",
    "    \"photo_url\": \"https://example.com/sightings/sight_2024_078.jpg\",\n",
    "    \"status\": \"New\",\n",
    "    \"priority\": \"High\",\n",
    "    \"verified\": False,\n",
    "    \"notes\": \"Witness is a regular jogger in the area and specifically noted the person matched the missing person flyers, person appeared to be having medical emergency consistent with diabetes, exact clothing match including distinctive tattoo on right arm\",\n",
    "}\n",
    "\n",
    "print(f\"üìã Sighting ID: {sample_sighting['id']}\")\n",
    "print(f\"üìã Sighting Number: {sample_sighting['sighting_number']}\")\n",
    "print(f\"üëÅÔ∏è Person Description: {sample_sighting['description'][:100]}...\")\n",
    "print(\n",
    "    f\"üìç Location: {sample_sighting['sighted_address']}, {sample_sighting['sighted_city']}\"\n",
    ")\n",
    "print(\n",
    "    f\"üìÖ Sighting Date: {sample_sighting['sighted_date']} at {sample_sighting['sighted_time']}\"\n",
    ")\n",
    "print(f\"üìû Witness: {sample_sighting['witness_name']}\")\n",
    "print(f\"‚≠ê Confidence Level: {sample_sighting['confidence_level']}\")\n",
    "print(f\"üö® Source Type: {sample_sighting['source_type']}\")\n",
    "print(f\"üî¥ Priority: {sample_sighting['priority']}\")\n",
    "print(f\"‚úÖ Verified: {sample_sighting['verified']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "gzdwe2p097b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a sighting that can be linked to the missing person\n",
    "SIGHTING_INSERT_QUERY = f\"\"\"\n",
    "MERGE `{DATASET_ID}.sightings` AS target\n",
    "USING (\n",
    "  SELECT\n",
    "    @id AS id,\n",
    "    @sighting_number AS sighting_number,\n",
    "    @description AS description,\n",
    "    @sighted_date AS sighted_date,\n",
    "    @sighted_time AS sighted_time,\n",
    "    @sighted_address AS sighted_address,\n",
    "    @sighted_city AS sighted_city,\n",
    "    @sighted_country AS sighted_country,\n",
    "    @sighted_postal_code AS sighted_postal_code,\n",
    "    @sighted_latitude AS sighted_latitude,\n",
    "    @sighted_longitude AS sighted_longitude,\n",
    "    CASE\n",
    "      WHEN @sighted_latitude IS NOT NULL AND @sighted_longitude IS NOT NULL\n",
    "      THEN ST_GEOGPOINT(@sighted_longitude, @sighted_latitude)\n",
    "      ELSE NULL\n",
    "    END AS sighted_geo,\n",
    "    @apparent_gender AS apparent_gender,\n",
    "    @apparent_age_range AS apparent_age_range,\n",
    "    @height_estimate AS height_estimate,\n",
    "    @hair_color AS hair_color,\n",
    "    @clothing_description AS clothing_description,\n",
    "    @distinguishing_features AS distinguishing_features,\n",
    "    @source_type AS source_type,\n",
    "    @witness_name AS witness_name,\n",
    "    @witness_phone AS witness_phone,\n",
    "    @witness_email AS witness_email,\n",
    "    @circumstances AS circumstances,\n",
    "    @confidence_level AS confidence_level,\n",
    "    @photo_url AS photo_url,\n",
    "    @status AS status,\n",
    "    @priority AS priority,\n",
    "    CAST(@verified AS BOOL) AS verified,\n",
    "    @notes AS notes,\n",
    "    CURRENT_TIMESTAMP() AS created_date,\n",
    "    CURRENT_TIMESTAMP() AS updated_date,\n",
    "    AI.GENERATE(\n",
    "      CONCAT(\n",
    "        'Generate a comprehensive summary paragraph for this sighting report for law enforcement analysis and matching purposes. ',\n",
    "        'Write it as a single, flowing, discursive paragraph without bullet points, lists, or structured formatting. ',\n",
    "        'Include key identifying features, location details in narrative form. ',\n",
    "        'Return only the summary paragraph without any introduction, conclusion, or additional commentary from the model. ',\n",
    "        'Sighting: ', @description, '. ',\n",
    "        'Observed on ', CAST(@sighted_date AS STRING),\n",
    "        CASE\n",
    "          WHEN @sighted_time IS NOT NULL THEN CONCAT(' at ', CAST(@sighted_time AS STRING))\n",
    "          ELSE ''\n",
    "        END,\n",
    "        ' in ', @sighted_city, ', ', @sighted_country, '. ',\n",
    "        'Location: ', @sighted_address,\n",
    "        CASE\n",
    "          WHEN @sighted_postal_code IS NOT NULL THEN CONCAT(', ', @sighted_postal_code)\n",
    "          ELSE ''\n",
    "        END,\n",
    "        '. Circumstances: ', @circumstances, '. ',\n",
    "        CASE\n",
    "          WHEN @notes IS NOT NULL THEN CONCAT('Additional notes: ', @notes, '. ')\n",
    "          ELSE ''\n",
    "        END,\n",
    "        'Status: ', @status, ', Priority: ', @priority, '.'\n",
    "      ),\n",
    "      connection_id => '{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}',\n",
    "      endpoint => 'gemini-2.5-flash',\n",
    "      model_params => JSON '{{\"generation_config\": {{\"temperature\": 0}}}}'\n",
    "    ).result AS ml_summary\n",
    ") AS source\n",
    "ON target.id = source.id\n",
    "WHEN NOT MATCHED THEN\n",
    "  INSERT (\n",
    "    id, sighting_number, description, sighted_date, sighted_time,\n",
    "    sighted_address, sighted_city, sighted_country, sighted_postal_code,\n",
    "    sighted_latitude, sighted_longitude, sighted_geo,\n",
    "    apparent_gender, apparent_age_range, height_estimate, hair_color,\n",
    "    clothing_description, distinguishing_features,\n",
    "    source_type, witness_name, witness_phone, witness_email,\n",
    "    circumstances, confidence_level, photo_url,\n",
    "    status, priority, verified, notes,\n",
    "    created_date, updated_date, ml_summary\n",
    "  )\n",
    "  VALUES (\n",
    "    source.id, source.sighting_number, source.description, source.sighted_date, source.sighted_time,\n",
    "    source.sighted_address, source.sighted_city, source.sighted_country, source.sighted_postal_code,\n",
    "    source.sighted_latitude, source.sighted_longitude, source.sighted_geo,\n",
    "    source.apparent_gender, source.apparent_age_range, source.height_estimate, source.hair_color,\n",
    "    source.clothing_description, source.distinguishing_features,\n",
    "    source.source_type, source.witness_name, source.witness_phone, source.witness_email,\n",
    "    source.circumstances, source.confidence_level, source.photo_url,\n",
    "    source.status, source.priority, source.verified, source.notes,\n",
    "    source.created_date, source.updated_date, source.ml_summary\n",
    "  );\n",
    "\"\"\"\n",
    "\n",
    "# Query to verify the record\n",
    "VERIFY_SIGHTING_RECORD_QUERY = f\"\"\"\n",
    "SELECT\n",
    "  id,\n",
    "  sighting_number,\n",
    "  description,\n",
    "  sighted_date,\n",
    "  sighted_time,\n",
    "  sighted_city,\n",
    "  apparent_gender,\n",
    "  apparent_age_range,\n",
    "  height_estimate,\n",
    "  clothing_description,\n",
    "  distinguishing_features,\n",
    "  source_type,\n",
    "  witness_name,\n",
    "  confidence_level,\n",
    "  status,\n",
    "  priority,\n",
    "  verified,\n",
    "  ml_summary\n",
    "FROM\n",
    "  `{DATASET_ID}.sightings`\n",
    "WHERE\n",
    "  id = @sighting_id\n",
    "LIMIT 1\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ctakt3tjsdi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting sighting record with AI-generated summary...\n",
      "‚úÖ Sighting record inserted successfully with AI-generated summary!\n",
      "üîë Sighting ID: 5945a5b3-9063-46b8-b5e8-63213571a028\n",
      "üìã Sighting Number: SIGHT-2024-070\n",
      "üëÅÔ∏è Description: 30 to 35-year-old male jogger, tall, near 70kg, brown hair, green eyes, wearing black jacket, blue j...\n",
      "üìç Location: San Francisco\n",
      "üö® Source Type: Witness\n",
      "üî¥ Priority: High\n",
      "‚úÖ Verified: False\n",
      "üîß Query job completed: d87f0dec-4590-41c9-a4ed-48fc523935d5\n",
      "\n",
      "================================================================================\n",
      "INSERTED SIGHTING RECORD WITH AI-GENERATED SUMMARY\n",
      "================================================================================\n",
      "üìã Sighting ID: 5945a5b3-9063-46b8-b5e8-63213571a028\n",
      "üìã Sighting Number: SIGHT-2024-070\n",
      "üëÅÔ∏è Description: 30 to 35-year-old male jogger, tall, near 70kg, brown hair, green eyes, wearing black jacket, blue jeans, white sneakers, has distinctive tattoo on right arm, appeared disoriented, matches missing diabetic runner from San Francisco\n",
      "üìÖ Date/Time: 2024-08-21 at 08:30:00\n",
      "üìç Location: San Francisco\n",
      "üë§ Person Details: Male, 30-40\n",
      "üìè Height: 175.0cm\n",
      "üëï Clothing: Black jacket, blue jeans, white sneakers\n",
      "üîç Features: Tattoo on right arm\n",
      "üö® Source: Witness\n",
      "üìû Witness: Maria Rodriguez\n",
      "‚≠ê Confidence: High\n",
      "üî¥ Priority: High\n",
      "üìä Status: New\n",
      "‚úÖ Verified: False\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "ü§ñ AI-GENERATED SIGHTING SUMMARY:\n",
      "--------------------------------------------------------------------------------\n",
      "On August 21, 2024, at approximately 08:30:00, a tall male jogger, estimated to be 30 to 35 years old and weighing around 70kg, with brown hair and green eyes, was observed in San Francisco's Golden Gate Park near the jogging trail (94117). This individual, wearing a black jacket, blue jeans, and white sneakers, and possessing a distinctive tattoo on his right arm, appeared disoriented and in medical distress, consistent with a diabetic episode, while sitting on a bench. The witness, a regular jogger in the area, specifically noted that this person's description, including the exact clothing and the unique right arm tattoo, precisely matched that of a high-priority missing diabetic runner, identified as John Doe, from San Francisco, who is known to require diabetes medication.\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Summary Statistics:\n",
      "   ‚Ä¢ Length: 787 characters\n",
      "   ‚Ä¢ Word count: 125 words\n",
      "   ‚Ä¢ Format: Discursive paragraph\n"
     ]
    }
   ],
   "source": [
    "# Execute the sighting insert query\n",
    "try:\n",
    "    print(\"Inserting sighting record with AI-generated summary...\")\n",
    "\n",
    "    # Configure the query job with parameters for sighting\n",
    "    sighting_job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\"id\", \"STRING\", sample_sighting[\"id\"]),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighting_number\", \"STRING\", sample_sighting[\"sighting_number\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"description\", \"STRING\", sample_sighting[\"description\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_date\", \"DATE\", sample_sighting[\"sighted_date\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_time\", \"TIME\", sample_sighting[\"sighted_time\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_address\", \"STRING\", sample_sighting[\"sighted_address\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_city\", \"STRING\", sample_sighting[\"sighted_city\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_country\", \"STRING\", sample_sighting[\"sighted_country\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_postal_code\",\n",
    "                \"STRING\",\n",
    "                sample_sighting[\"sighted_postal_code\"],\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_latitude\", \"FLOAT64\", sample_sighting[\"sighted_latitude\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_longitude\", \"FLOAT64\", sample_sighting[\"sighted_longitude\"]\n",
    "            ),\n",
    "            # Person Description fields\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"apparent_gender\", \"STRING\", sample_sighting[\"apparent_gender\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"apparent_age_range\", \"STRING\", sample_sighting[\"apparent_age_range\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"height_estimate\", \"FLOAT64\", sample_sighting[\"height_estimate\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"hair_color\", \"STRING\", sample_sighting[\"hair_color\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"clothing_description\", \"STRING\", sample_sighting[\"clothing_description\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"distinguishing_features\", \"STRING\", sample_sighting[\"distinguishing_features\"]\n",
    "            ),\n",
    "            # Source Information fields\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"source_type\", \"STRING\", sample_sighting[\"source_type\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"witness_name\", \"STRING\", sample_sighting[\"witness_name\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"witness_phone\", \"STRING\", sample_sighting[\"witness_phone\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"witness_email\", \"STRING\", sample_sighting[\"witness_email\"]\n",
    "            ),\n",
    "            # Sighting Details\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"circumstances\", \"STRING\", sample_sighting[\"circumstances\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"confidence_level\", \"STRING\", sample_sighting[\"confidence_level\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"photo_url\", \"STRING\", sample_sighting[\"photo_url\"]\n",
    "            ),\n",
    "            # Status and Processing fields\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"status\", \"STRING\", sample_sighting[\"status\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"priority\", \"STRING\", sample_sighting[\"priority\"]\n",
    "            ),\n",
    "            # Convert Python boolean to BigQuery boolean string\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"verified\", \"STRING\", \"TRUE\" if sample_sighting[\"verified\"] else \"FALSE\"\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"notes\", \"STRING\", sample_sighting[\"notes\"]\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Execute the sighting insert query\n",
    "    query_job = client.query(SIGHTING_INSERT_QUERY, job_config=sighting_job_config)\n",
    "    results = query_job.result()  # Wait for the query to complete\n",
    "\n",
    "    print(\"‚úÖ Sighting record inserted successfully with AI-generated summary!\")\n",
    "    print(f\"üîë Sighting ID: {sample_sighting['id']}\")\n",
    "    print(f\"üìã Sighting Number: {sample_sighting['sighting_number']}\")\n",
    "    print(f\"üëÅÔ∏è Description: {sample_sighting['description'][:100]}...\")\n",
    "    print(f\"üìç Location: {sample_sighting['sighted_city']}\")\n",
    "    print(f\"üö® Source Type: {sample_sighting['source_type']}\")\n",
    "    print(f\"üî¥ Priority: {sample_sighting['priority']}\")\n",
    "    print(f\"‚úÖ Verified: {sample_sighting['verified']}\")\n",
    "    print(f\"üîß Query job completed: {query_job.job_id}\")\n",
    "\n",
    "    # Verify the inserted record\n",
    "    verify_job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighting_id\", \"STRING\", sample_sighting[\"id\"]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    verify_job = client.query(VERIFY_SIGHTING_RECORD_QUERY, job_config=verify_job_config)\n",
    "    verify_results = verify_job.result()\n",
    "\n",
    "    if verify_results.total_rows > 0:\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"INSERTED SIGHTING RECORD WITH AI-GENERATED SUMMARY\")\n",
    "        print(\"=\" * 80)\n",
    "\n",
    "        for row in verify_results:\n",
    "            print(f\"üìã Sighting ID: {row.id}\")\n",
    "            print(f\"üìã Sighting Number: {row.sighting_number}\")\n",
    "            print(f\"üëÅÔ∏è Description: {row.description}\")\n",
    "            print(f\"üìÖ Date/Time: {row.sighted_date} at {row.sighted_time}\")\n",
    "            print(f\"üìç Location: {row.sighted_city}\")\n",
    "            print(f\"üë§ Person Details: {row.apparent_gender}, {row.apparent_age_range}\")\n",
    "            print(f\"üìè Height: {row.height_estimate}cm\")\n",
    "            print(f\"üëï Clothing: {row.clothing_description}\")\n",
    "            print(f\"üîç Features: {row.distinguishing_features}\")\n",
    "            print(f\"üö® Source: {row.source_type}\")\n",
    "            print(f\"üìû Witness: {row.witness_name}\")\n",
    "            print(f\"‚≠ê Confidence: {row.confidence_level}\")\n",
    "            print(f\"üî¥ Priority: {row.priority}\")\n",
    "            print(f\"üìä Status: {row.status}\")\n",
    "            print(f\"‚úÖ Verified: {row.verified}\")\n",
    "\n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "            print(\"ü§ñ AI-GENERATED SIGHTING SUMMARY:\")\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"{row.ml_summary}\")\n",
    "            print(\"-\" * 80)\n",
    "\n",
    "            # Calculate summary statistics\n",
    "            summary_length = len(row.ml_summary) if row.ml_summary else 0\n",
    "            word_count = len(row.ml_summary.split()) if row.ml_summary else 0\n",
    "            print(\"\\nüìä Summary Statistics:\")\n",
    "            print(f\"   ‚Ä¢ Length: {summary_length} characters\")\n",
    "            print(f\"   ‚Ä¢ Word count: {word_count} words\")\n",
    "            print(f\"   ‚Ä¢ Format: {'Discursive paragraph' if summary_length > 100 else 'Short summary'}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing sighting insert query: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d046a61",
   "metadata": {},
   "source": [
    "# üß† AI embedding generation\n",
    "\n",
    "This section demonstrates the creation of embeddings from missing and sighings summaries through BigQuery. Embeddings are numerical representations that capture the characteristics of provided data, enabling similarity matching and semantic search capabilities.\n",
    "\n",
    "ü§ñ **Technical process:**\n",
    "- Stores embeddings in BigQuery for scalable similarity search\n",
    "- Enables semantic matching beyond simple textual comparison\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "seitbchp88i",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Embedding update queries prepared!\n",
      "üß† These queries will calculate embeddings for:\n",
      "   ‚Ä¢ Missing persons table (id, ml_summary field)\n",
      "   ‚Ä¢ Sightings table (id, ml_summary field)\n",
      "üìä Using the BigQuery ML text embedding model: homeward.text_embedding_model\n"
     ]
    }
   ],
   "source": [
    "# Calculate embeddings for missing persons table\n",
    "UPDATE_MISSING_PERSONS_EMBEDDINGS_QUERY = f\"\"\"\n",
    "UPDATE `{DATASET_ID}.missing_persons` AS mp\n",
    "SET mp.ml_summary_embedding = e.ml_generate_embedding_result\n",
    "FROM ML.GENERATE_EMBEDDING(\n",
    "    MODEL `{DATASET_ID}.text_embedding_model`,\n",
    "    (SELECT id, ml_summary as content FROM `{DATASET_ID}.missing_persons` WHERE ml_summary IS NOT NULL AND (ml_summary_embedding IS NULL OR ARRAY_LENGTH(ml_summary_embedding) = 0)),\n",
    "    STRUCT('SEMANTIC_SIMILARITY' as task_type)\n",
    ") as e\n",
    "WHERE mp.id = e.id;\n",
    "\"\"\"\n",
    "\n",
    "# Calculate embeddings for sightings table\n",
    "UPDATE_SIGHTINGS_EMBEDDINGS_QUERY = f\"\"\"\n",
    "UPDATE `{DATASET_ID}.sightings` as s\n",
    "SET s.ml_summary_embedding = e.ml_generate_embedding_result\n",
    "FROM ML.GENERATE_EMBEDDING(\n",
    "    MODEL `{DATASET_ID}.text_embedding_model`,\n",
    "    (SELECT id, ml_summary as content FROM `{DATASET_ID}.sightings` WHERE ml_summary IS NOT NULL AND (ml_summary_embedding IS NULL OR ARRAY_LENGTH(ml_summary_embedding) = 0)),\n",
    "    STRUCT('SEMANTIC_SIMILARITY' as task_type)\n",
    ") as e\n",
    "WHERE e.id = s.id;\n",
    "\"\"\"\n",
    "\n",
    "print(\"‚úÖ Embedding update queries prepared!\")\n",
    "print(\"üß† These queries will calculate embeddings for:\")\n",
    "print(\"   ‚Ä¢ Missing persons table (id, ml_summary field)\")\n",
    "print(\"   ‚Ä¢ Sightings table (id, ml_summary field)\")\n",
    "print(f\"üìä Using the BigQuery ML text embedding model: {DATASET_ID}.text_embedding_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "018e99c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFY_EMBEDDING_QUERY = f\"\"\"\n",
    "SELECT\n",
    "    'missing_persons' as table_name,\n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(ml_summary_embedding) as records_with_embeddings,\n",
    "    ROUND(COUNT(ml_summary_embedding) * 100.0 / COUNT(*), 2) as embedding_coverage_pct\n",
    "FROM `{DATASET_ID}.missing_persons`\n",
    "UNION ALL\n",
    "SELECT\n",
    "    'sightings' as table_name,\n",
    "    COUNT(*) as total_records,\n",
    "    COUNT(ml_summary_embedding) as records_with_embeddings,\n",
    "    ROUND(COUNT(ml_summary_embedding) * 100.0 / COUNT(*), 2) as embedding_coverage_pct\n",
    "FROM `{DATASET_ID}.sightings`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ntburm0v",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating embeddings for missing persons table...\n",
      "‚úÖ Missing persons embeddings updated! Rows modified: 1\n",
      "\n",
      "Calculating embeddings for sightings table...\n",
      "‚úÖ Sightings embeddings updated! Rows modified: 1\n"
     ]
    }
   ],
   "source": [
    "# Execute embedding calculations for both tables\n",
    "try:\n",
    "    print(\"Calculating embeddings for missing persons table...\")\n",
    "\n",
    "    # Update missing persons embeddings\n",
    "    mp_job = client.query(UPDATE_MISSING_PERSONS_EMBEDDINGS_QUERY)\n",
    "    mp_results = mp_job.result()\n",
    "    print(\n",
    "        f\"‚úÖ Missing persons embeddings updated! Rows modified: {mp_job.num_dml_affected_rows}\"\n",
    "    )\n",
    "\n",
    "    print(\"\\nCalculating embeddings for sightings table...\")\n",
    "\n",
    "    # Update sightings embeddings\n",
    "    sightings_job = client.query(UPDATE_SIGHTINGS_EMBEDDINGS_QUERY)\n",
    "    sightings_results = sightings_job.result()\n",
    "    print(\n",
    "        f\"‚úÖ Sightings embeddings updated! Rows modified: {sightings_job.num_dml_affected_rows}\"\n",
    "    )\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error calculating embeddings: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7fd6499f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "EMBEDDING CALCULATION SUMMARY\n",
      "================================================================================\n",
      "üìä Table: missing_persons\n",
      "   Total Records: 1\n",
      "   Records with Embeddings: 1\n",
      "   Coverage: 100.0%\n",
      "\n",
      "üìä Table: sightings\n",
      "   Total Records: 1\n",
      "   Records with Embeddings: 1\n",
      "   Coverage: 100.0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "\n",
    "    # Verify embeddings were created\n",
    "    verify_job = client.query(VERIFY_EMBEDDING_QUERY)\n",
    "    verify_results = verify_job.result()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"EMBEDDING CALCULATION SUMMARY\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    for row in verify_results:\n",
    "        print(f\"üìä Table: {row.table_name}\")\n",
    "        print(f\"   Total Records: {row.total_records}\")\n",
    "        print(f\"   Records with Embeddings: {row.records_with_embeddings}\")\n",
    "        print(f\"   Coverage: {row.embedding_coverage_pct}%\")\n",
    "        print()\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error checking embeddings: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6bed30",
   "metadata": {},
   "source": [
    "---\n",
    "# üìä Vector Search Index Optimization\n",
    "\n",
    "**‚ö†Ô∏è Performance optimization - Run only if you have imported more than 5,000 examples (importing your custom data) ‚ö†Ô∏è**\n",
    "\n",
    "This section creates vector indexes to accelerate similarity search operations when working with large datasets. Vector indexes dramatically improve query performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d24165f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING_PERSON_VECTOR_INDEX = f\"\"\"\n",
    "CREATE OR REPLACE VECTOR INDEX missing_person_v_index\n",
    "ON `{DATASET_ID}.missing_persons`(ml_summary_embedding)\n",
    "OPTIONS(\n",
    "  index_type = 'IVF',\n",
    "  distance_type = 'COSINE',\n",
    "  ivf_options = '{{\"num_lists\":500}}'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "SIGHTING_VECTOR_INDEX = f\"\"\"\n",
    "CREATE OR REPLACE VECTOR INDEX sighting_v_index\n",
    "ON `{DATASET_ID}.missing_persons`(ml_summary_embedding)\n",
    "OPTIONS(\n",
    "  index_type = 'IVF',\n",
    "  distance_type = 'COSINE',\n",
    "  ivf_options = '{{\"num_lists\":500}}'\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "# Execute vector index creation queries\n",
    "try:\n",
    "    print(\"Creating vector index for missing persons table...\")\n",
    "    \n",
    "    # Create missing persons vector index\n",
    "    mp_index_job = client.query(MISSING_PERSON_VECTOR_INDEX)\n",
    "    mp_index_results = mp_index_job.result()\n",
    "    print(\"‚úÖ Missing persons vector index created successfully!\")\n",
    "    \n",
    "    print(\"\\nCreating vector index for sightings table...\")\n",
    "    \n",
    "    # Create sightings vector index\n",
    "    sightings_index_job = client.query(SIGHTING_VECTOR_INDEX)\n",
    "    sightings_index_results = sightings_index_job.result()\n",
    "    print(\"‚úÖ Sightings vector index created successfully!\")\n",
    "    \n",
    "    print(\"\\nüéØ Tables are now optimized for fast similarity searches\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error creating vector indexes: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, 'errors') and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08bd211",
   "metadata": {},
   "source": [
    "---\n",
    "# üîç Find Sightings by Missing Person (AI Similarity Search)\n",
    "\n",
    "This section demonstrates how to search for potential sightings of a specific missing person using similarity matching. The query compares the missing person's AI-generated summary against all recorded sightings in the same area to identify possible matches.\n",
    "\n",
    "üéØ **Search methodology:**\n",
    "- Compares missing person description embeddings with sighting embeddings, filtering by geographic proximity and time constraints\n",
    "- Calculates similarity scores using vector similarity\n",
    "- Ranks results by confidence level and temporal relevance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "sro2qpo9j5k",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç This query will find sightings that match our missing person John Doe\n",
      "üìä Results include:\n",
      "   ‚Ä¢ Cosine distance (0-2, lower = better match)\n",
      "   ‚Ä¢ Top 5 most similar sightings\n",
      "   ‚Ä¢ Geo filtering based on configurable search radius from last seen location\n",
      "   ‚Ä¢ Time filtering to search from delta_days before last_seen_date to 30 days after based on created_date\n"
     ]
    }
   ],
   "source": [
    "# Similarity Search 1: Find sightings that match a missing person\n",
    "SIMILARITY_SEARCH_MP_TO_SIGHTINGS_QUERY = f\"\"\"\n",
    "-- Search sightings that are similar to a specific missing person with geo and time filtering\n",
    "SELECT\n",
    "query.id,\n",
    "query.case_number,\n",
    "distance,\n",
    "base.id,\n",
    "base.sighting_number,\n",
    "base.sighted_date,\n",
    "base.sighted_time,\n",
    "base.sighted_city,\n",
    "base.sighted_geo,\n",
    "base.witness_name,\n",
    "base.confidence_level,\n",
    "base.ml_summary\n",
    "FROM\n",
    "  VECTOR_SEARCH(\n",
    "    (\n",
    "      SELECT *\n",
    "      FROM \n",
    "        `{DATASET_ID}.sightings`\n",
    "      WHERE\n",
    "        DATE(created_date) >= DATE_SUB(@last_seen_date, INTERVAL @delta_days DAY)\n",
    "    ),\n",
    "    'ml_summary_embedding',\n",
    "    (SELECT id, case_number, ml_summary_embedding FROM `{DATASET_ID}.missing_persons` WHERE id = @missing_person_id), \n",
    "    top_k => 5,\n",
    "    distance_type => 'COSINE',\n",
    "    options => '{{\"fraction_lists_to_search\": 0.005}}')\n",
    "WHERE ST_DWITHIN(\n",
    "  base.sighted_geo, \n",
    "  ST_GEOGPOINT(@last_seen_longitude, @last_seen_latitude), \n",
    "  @search_radius_meters\n",
    ");\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç This query will find sightings that match our missing person John Doe\")\n",
    "print(\"üìä Results include:\")\n",
    "print(\"   ‚Ä¢ Cosine distance (0-2, lower = better match)\")\n",
    "print(\"   ‚Ä¢ Top 5 most similar sightings\")\n",
    "print(\"   ‚Ä¢ Geo filtering based on configurable search radius from last seen location\")\n",
    "print(\"   ‚Ä¢ Time filtering to search from delta_days before last_seen_date to 30 days after based on created_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cgxd0y1wnso",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for sightings that match our missing person John Doe...\n",
      "‚úÖ Similarity search completed! Found 1 potential matches\n",
      "\n",
      "====================================================================================================\n",
      "SIMILARITY SEARCH RESULTS: MISSING PERSON ‚Üí SIGHTINGS\n",
      "====================================================================================================\n",
      "üîç Searching for: John Doe (Case: CASE-2025-0901-0001)\n",
      "====================================================================================================\n",
      "\n",
      "üéØ MATCH #1\n",
      "--------------------------------------------------\n",
      "üìã Sighting: SIGHT-2024-070 | üìè Distance: 0.10458744903004302\n",
      "üìÖ Date/Time: 2024-08-21 at 08:30:00\n",
      "üìç Location: San Francisco\n",
      "üìû Witness: Maria Rodriguez | ‚≠ê Reliability: High\n",
      "\n",
      "ü§ñ Sighting Summary:\n",
      "   On August 21, 2024, at approximately 08:30:00, a tall male jogger, estimated to be 30 to 35 years old and weighing around 70kg, with brown hair and gr...\n",
      "‚ö†Ô∏è GOOD MATCH - Worth investigating\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute similarity search: Missing Person ‚Üí Sightings\n",
    "try:\n",
    "    print(\"üîç Searching for sightings that match our missing person John Doe...\")\n",
    "\n",
    "    # Configure query with missing person ID parameter and geo filtering\n",
    "    search_job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"missing_person_id\", \"STRING\", sample_missing_person[\"id\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_latitude\", \"FLOAT64\", sample_missing_person[\"last_seen_latitude\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_longitude\", \"FLOAT64\", sample_missing_person[\"last_seen_longitude\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"search_radius_meters\", \"FLOAT64\", 10000.0  # 10km search radius\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"last_seen_date\", \"DATE\", sample_missing_person[\"last_seen_date\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"delta_days\", \"INT64\", 7  # Search 7 days before last seen date\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Execute the similarity search query\n",
    "    search_job = client.query(\n",
    "        SIMILARITY_SEARCH_MP_TO_SIGHTINGS_QUERY, job_config=search_job_config\n",
    "    )\n",
    "    search_results = search_job.result()\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ Similarity search completed! Found {search_results.total_rows} potential matches\"\n",
    "    )\n",
    "\n",
    "    if search_results.total_rows > 0:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"SIMILARITY SEARCH RESULTS: MISSING PERSON ‚Üí SIGHTINGS\")\n",
    "        print(\"=\" * 100)\n",
    "        print(\n",
    "            f\"üîç Searching for: {sample_missing_person['name']} {sample_missing_person['surname']} (Case: {sample_missing_person['case_number']})\"\n",
    "        )\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        for i, row in enumerate(search_results, 1):\n",
    "            print(f\"\\nüéØ MATCH #{i}\")\n",
    "            print(\"-\" * 50)\n",
    "            print(\n",
    "                f\"üìã Sighting: {row.sighting_number} | üìè Distance: {row.distance}\"\n",
    "            )\n",
    "            print(f\"üìÖ Date/Time: {row.sighted_date} at {row.sighted_time}\")\n",
    "            print(f\"üìç Location: {row.sighted_city}\")\n",
    "            print(\n",
    "                f\"üìû Witness: {row.witness_name} | ‚≠ê Reliability: {row.confidence_level}\"\n",
    "            )\n",
    "\n",
    "            print(\"\\nü§ñ Sighting Summary:\")\n",
    "            print(f\"   {row.ml_summary[:150]}...\")\n",
    "\n",
    "            if row.distance <= 0.1:\n",
    "                print(\"üö® HIGH PRIORITY MATCH - Recommend immediate investigation!\")\n",
    "            elif row.distance <= 0.3:\n",
    "                print(\"‚ö†Ô∏è GOOD MATCH - Worth investigating\")\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No sighting matches found for this missing person\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing similarity search: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74988c94",
   "metadata": {},
   "source": [
    "# üîÑ Identify missing persons from sightings (reverse similarity search)\n",
    "\n",
    "This section demonstrates the reverse search capability - identifying which missing persons might match a newly reported sighting. \n",
    "\n",
    "üîÑ **Reverse matching process:**\n",
    "- Takes the embedding of a sighting description and compares against all missing person cases that have been reported in compatible area and time\n",
    "\n",
    "üìä **Output provides:** Ranked list of possible missing person matches with confidence scores, case details, and investigative contact information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "yyosvki10lf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç This query will find missing persons that match our sighting\n",
      "üìä Results include:\n",
      "   ‚Ä¢ Cosine distance (0-2, lower = better match)\n",
      "   ‚Ä¢ Top 10 most similar missing persons\n",
      "   ‚Ä¢ Geo filtering based on configurable search radius from sighting location\n",
      "   ‚Ä¢ Time filtering to search from delta_days before sighted_date to 30 days after based on created_date\n"
     ]
    }
   ],
   "source": [
    "# Similarity Search: Find missing persons that match a sighting\n",
    "SIMILARITY_SEARCH_SIGHTINGS_TO_MP_QUERY = f\"\"\"\n",
    "-- Search missing persons that are similar to a specific sighting with geo and time filtering\n",
    "SELECT\n",
    "query.id,\n",
    "query.sighting_number,\n",
    "distance,\n",
    "base.id,\n",
    "base.case_number,\n",
    "base.name,\n",
    "base.surname,\n",
    "base.ml_summary\n",
    "FROM\n",
    "  VECTOR_SEARCH(\n",
    "    (\n",
    "      SELECT *\n",
    "      FROM \n",
    "        `{DATASET_ID}.missing_persons`\n",
    "      WHERE\n",
    "        DATE(created_date) >= DATE_SUB(@sighted_date, INTERVAL @delta_days DAY)\n",
    "    ),\n",
    "    'ml_summary_embedding',\n",
    "    (SELECT id, sighting_number, ml_summary_embedding FROM `{DATASET_ID}.sightings` WHERE id = @sighting_id), \n",
    "    top_k => 10,\n",
    "    distance_type => 'COSINE',\n",
    "    options => '{{\"fraction_lists_to_search\": 0.005}}')\n",
    "WHERE ST_DWITHIN(\n",
    "  base.last_seen_geo, \n",
    "  ST_GEOGPOINT(@sighted_longitude, @sighted_latitude), \n",
    "  @search_radius_meters\n",
    ");\n",
    "\"\"\"\n",
    "\n",
    "print(\"üîç This query will find missing persons that match our sighting\")\n",
    "print(\"üìä Results include:\")\n",
    "print(\"   ‚Ä¢ Cosine distance (0-2, lower = better match)\")\n",
    "print(\"   ‚Ä¢ Top 10 most similar missing persons\")\n",
    "print(\"   ‚Ä¢ Geo filtering based on configurable search radius from sighting location\")\n",
    "print(\"   ‚Ä¢ Time filtering to search from delta_days before sighted_date to 30 days after based on created_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "o9q659lohh",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for missing persons that match our sighting...\n",
      "‚úÖ  Similarity search completed! Found 1 potential matches\n",
      "\n",
      "====================================================================================================\n",
      "SIMILARITY SEARCH RESULTS: SIGHTING ‚Üí MISSING PERSONS\n",
      "====================================================================================================\n",
      "üîç Analyzing sighting: SIGHT-2024-070\n",
      "====================================================================================================\n",
      "\n",
      "üéØ MATCH #1\n",
      "--------------------------------------------------\n",
      "üìã Case: CASE-2025-0901-0001 | üìè Distance: 0.10458744903004302\n",
      "üë§ Missing Person: John Doe\n",
      "\n",
      "ü§ñ Missing Person Summary:\n",
      "   John Doe, a 35-year-old male, was last seen on September 1, 2025, at approximately 18:45:00 in San Francisco, USA, specifically at 456 Oak Avenue, 941...\n",
      "‚ö†Ô∏è GOOD MATCH - Worth investigating further\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Execute similarity search: Sighting ‚Üí Missing Persons\n",
    "try:\n",
    "    print(\"üîç Searching for missing persons that match our sighting...\")\n",
    "\n",
    "    # Configure query with sighting ID parameter and geo filtering\n",
    "    reverse_search_job_config = bigquery.QueryJobConfig(\n",
    "        query_parameters=[\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighting_id\", \"STRING\", sample_sighting[\"id\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_latitude\", \"FLOAT64\", sample_sighting[\"sighted_latitude\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_longitude\", \"FLOAT64\", sample_sighting[\"sighted_longitude\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"search_radius_meters\", \"FLOAT64\", 10000.0  # 10km search radius\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"sighted_date\", \"DATE\", sample_sighting[\"sighted_date\"]\n",
    "            ),\n",
    "            bigquery.ScalarQueryParameter(\n",
    "                \"delta_days\", \"INT64\", 7  # Search 7 days before sighted date\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Execute the reverse similarity search query\n",
    "    reverse_search_job = client.query(\n",
    "        SIMILARITY_SEARCH_SIGHTINGS_TO_MP_QUERY, job_config=reverse_search_job_config\n",
    "    )\n",
    "    reverse_search_results = reverse_search_job.result()\n",
    "\n",
    "    print(\n",
    "        f\"‚úÖ  Similarity search completed! Found {reverse_search_results.total_rows} potential matches\"\n",
    "    )\n",
    "\n",
    "    if reverse_search_results.total_rows > 0:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"SIMILARITY SEARCH RESULTS: SIGHTING ‚Üí MISSING PERSONS\")\n",
    "        print(\"=\" * 100)\n",
    "        print(\n",
    "            f\"üîç Analyzing sighting: {sample_sighting['sighting_number']}\"\n",
    "        )\n",
    "        print(\"=\" * 100)\n",
    "\n",
    "        for i, row in enumerate(reverse_search_results, 1):\n",
    "            print(f\"\\nüéØ MATCH #{i}\")\n",
    "            print(\"-\" * 50)\n",
    "            print(\n",
    "                f\"üìã Case: {row.case_number} | üìè Distance: {row.distance}\"\n",
    "            )\n",
    "            print(f\"üë§ Missing Person: {row.name} {row.surname}\")\n",
    "\n",
    "            print(\"\\nü§ñ Missing Person Summary:\")\n",
    "            print(f\"   {row.ml_summary[:150]}...\")\n",
    "\n",
    "            if row.distance <= 0.1:\n",
    "                print(\"üö® HIGH PRIORITY MATCH - Strong potential identification!\")\n",
    "            elif row.distance <= 0.3:\n",
    "                print(\"‚ö†Ô∏è GOOD MATCH - Worth investigating further\")\n",
    "\n",
    "            print(\"-\" * 50)\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No missing person matches found for this sighting\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing reverse similarity search: {str(e)}\")\n",
    "    print(f\"Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"Error details: {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c03368a",
   "metadata": {},
   "source": [
    "# üìπ AI-Powered Surveillance Video Analysis\n",
    "This section showcases the demo most advanced capability - automatically analyzing surveillance camera footage to detect and match missing persons. Using Google's Gemini multimodal AI, the system can process video content and identify potential matches.\n",
    "\n",
    "üé• **Video analysis capabilities:**\n",
    "- Processes surveillance footage from multiple camera sources\n",
    "- Extracts individual frames and identifies human figures\n",
    "- Compares detected persons against missing person databases\n",
    "- Generates confidence scores and location metadata\n",
    "\n",
    "üèôÔ∏è **Smart city integration:**\n",
    "This technology enables law enforcement to leverage existing surveillance infrastructure across entire metropolitan areas, automatically scanning thousands of hours of footage for missing persons.\n",
    "\n",
    "‚ö° **Real-world impact:** Transforms passive surveillance systems into active search tools, dramatically expanding the search radius and reducing time to locate missing individuals.\n",
    "\n",
    "‚è±Ô∏è **Processing speed:** Analyzes video content at 2-5x real-time speed, depending on resolution and system load."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa730c12",
   "metadata": {},
   "source": [
    "# ‚¨áÔ∏è Recordings download\n",
    "\n",
    "This section demonstrates the video ingestion pipeline of the missing persons detection system by using a Free dataset that contains recordings. For this specific scenario, to save time and costs i used the lowest resolution found in the dataset, as a consequence Gemini is not always able to correctly detect the person as described in the above example. For this reason I added also a video i realized myself, but you can use whichever video you prefer.\n",
    "\n",
    "**What you will find in this section**\n",
    "\n",
    "1. **Download VIRAT dataset samples**: Retrieve sample surveillance videos from the VIRAT Video and Image Dataset Release 2.0, which contains realistic scenarios of people in various outdoor environments. These videos are temporarily stored locally for processing.\n",
    "\n",
    "2. **Upload to Google Cloud Storage with metadata enrichment**: Each video is uploaded to the GCS bucket together with metadata headers including camera information, geolocation data, timestamps, and technical specifications.\n",
    "\n",
    "3. **Create BigQuery External Table**: a BigQuery external table that directly references the video files in GCS, enabling SQL-based querying and Gemini multimodal processing.\n",
    "\n",
    "*Note: During development, I encountered metadata cache invalidation issues when creating the external table before uploading files. For this reason i decided to upload files first, then create the table, as the external table will already retrieve all the metadata needed by GCS. All encountered limitations and workarounds are documented in our technical limitations document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "842662e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIRAT_VIDEO_SAMPLES = {\n",
    "  \"metadata\": {\n",
    "    \"source\": \"https://data.kitware.com/#collection/56f56db28d777f753209ba9f/folder/56f581ce8d777f753209ca43\",\n",
    "    \"dataset\": \"VIRAT Video and Image Dataset Release 2.0\",\n",
    "    \"created_at\": \"2025-08-18T00:00:00Z\",\n",
    "    \"version\": \"1.0\"\n",
    "  },\n",
    "  \"videos\": [\n",
    "    {\n",
    "      \"id\": \"56f587eb8d777f753209cc12\",\n",
    "      \"download_url\": \"https://data.kitware.com/api/v1/item/56f587eb8d777f753209cc12/download\",\n",
    "      \"camera_id\": \"CAM001\",\n",
    "      \"timestamp\": \"20240815123000\",\n",
    "      \"latitude\": 37.7849,\n",
    "      \"longitude\": -122.4094,\n",
    "      \"camera_type\": \"VIRAT_OPENDATA\",\n",
    "      \"resolution\": \"1920x1080\",\n",
    "      \"location\": \"San_Francisco\",\n",
    "      \"duration_seconds\": 420,\n",
    "      \"mime_type\": \"video/mp4\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"56f587ca8d777f753209cbb2\",\n",
    "      \"download_url\": \"https://data.kitware.com/api/v1/item/56f587ca8d777f753209cbb2/download\",\n",
    "      \"camera_id\": \"CAM002\",\n",
    "      \"timestamp\": \"20240815140000\",\n",
    "      \"latitude\": 37.7849,\n",
    "      \"longitude\": -122.4094,\n",
    "      \"camera_type\": \"VIRAT_OPENDATA\",\n",
    "      \"resolution\": \"1920x1080\",\n",
    "      \"location\": \"San_Francisco\",\n",
    "      \"duration_seconds\": 360,\n",
    "      \"mime_type\": \"video/mp4\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"56f587a98d777f753209cb6d\",\n",
    "      \"download_url\": \"https://data.kitware.com/api/v1/item/56f587a98d777f753209cb6d/download\",\n",
    "      \"camera_id\": \"CAM003\",\n",
    "      \"timestamp\": \"20240815153000\",\n",
    "      \"latitude\": 37.7849,\n",
    "      \"longitude\": -122.4094,\n",
    "      \"camera_type\": \"VIRAT_OPENDATA\",\n",
    "      \"resolution\": \"1920x1080\",\n",
    "      \"location\": \"San_Francisco\",\n",
    "      \"duration_seconds\": 480,\n",
    "      \"mime_type\": \"video/mp4\"\n",
    "    },\n",
    "    {\n",
    "      \"id\": \"56f5878c8d777f753209caf2\",\n",
    "      \"download_url\": \"https://data.kitware.com/api/v1/item/56f5878c8d777f753209caf2/download\",\n",
    "      \"camera_id\": \"CAM004\",\n",
    "      \"timestamp\": \"20240815170000\",\n",
    "      \"latitude\": 37.7849,\n",
    "      \"longitude\": -122.4094,\n",
    "      \"camera_type\": \"VIRAT_OPENDATA\",\n",
    "      \"resolution\": \"1920x1080\",\n",
    "      \"location\": \"San_Francisco\",\n",
    "      \"duration_seconds\": 390,\n",
    "      \"mime_type\": \"video/mp4\"\n",
    "    }\n",
    "  ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "885ec5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Download video samples ===\n",
      "Using temporary directory: /var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta\n",
      "\n",
      "Processing video 1/4: 56f587eb8d777f753209cc12\n",
      "  Filename: CAM001_20240815123000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "  Downloading from: https://data.kitware.com/api/v1/item/56f587eb8d777f753209cc12/download\n",
      "‚úÖ Success: curl -L -f -o \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM001_20240815123000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"https://data.kitware.com/api/v1/item/56f587eb8d777f753209cc12/download\" --connect-timeout 30 --max-time 300\n",
      "  Download completed: 3.6M\n",
      "\n",
      "=== Upload video samples to GCS ===\n",
      "  Uploading video to GCS with metadata...\n",
      "‚úÖ Success: \n",
      "gsutil -h \"Content-Type:video/mp4\"  -h \"x-goog-meta-video-id:56f587eb8d777f753209cc12\"  -h \"x-goog-meta-camera-id:CAM001\"  -h \"x-goog-meta-timestamp:20240815123000\"  -h \"x-goog-meta-latitude:37.7849\"  -h \"x-goog-meta-longitude:-122.4094\"  -h \"x-goog-meta-camera-type:VIRAT_OPENDATA\"  -h \"x-goog-meta-resolution:1920x1080\"  cp \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM001_20240815123000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"gs://homeward_videos_7fde5434/CAM001_20240815123000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\"\n",
      "\n",
      "  Video uploaded successfully with metadata\n",
      "\n",
      "Processing video 2/4: 56f587ca8d777f753209cbb2\n",
      "  Filename: CAM002_20240815140000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "  Downloading from: https://data.kitware.com/api/v1/item/56f587ca8d777f753209cbb2/download\n",
      "‚úÖ Success: curl -L -f -o \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM002_20240815140000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"https://data.kitware.com/api/v1/item/56f587ca8d777f753209cbb2/download\" --connect-timeout 30 --max-time 300\n",
      "  Download completed: 3.7M\n",
      "\n",
      "=== Upload video samples to GCS ===\n",
      "  Uploading video to GCS with metadata...\n",
      "‚úÖ Success: \n",
      "gsutil -h \"Content-Type:video/mp4\"  -h \"x-goog-meta-video-id:56f587ca8d777f753209cbb2\"  -h \"x-goog-meta-camera-id:CAM002\"  -h \"x-goog-meta-timestamp:20240815140000\"  -h \"x-goog-meta-latitude:37.7849\"  -h \"x-goog-meta-longitude:-122.4094\"  -h \"x-goog-meta-camera-type:VIRAT_OPENDATA\"  -h \"x-goog-meta-resolution:1920x1080\"  cp \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM002_20240815140000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"gs://homeward_videos_7fde5434/CAM002_20240815140000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\"\n",
      "\n",
      "  Video uploaded successfully with metadata\n",
      "\n",
      "Processing video 3/4: 56f587a98d777f753209cb6d\n",
      "  Filename: CAM003_20240815153000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "  Downloading from: https://data.kitware.com/api/v1/item/56f587a98d777f753209cb6d/download\n",
      "‚úÖ Success: curl -L -f -o \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM003_20240815153000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"https://data.kitware.com/api/v1/item/56f587a98d777f753209cb6d/download\" --connect-timeout 30 --max-time 300\n",
      "  Download completed: 3.1M\n",
      "\n",
      "=== Upload video samples to GCS ===\n",
      "  Uploading video to GCS with metadata...\n",
      "‚úÖ Success: \n",
      "gsutil -h \"Content-Type:video/mp4\"  -h \"x-goog-meta-video-id:56f587a98d777f753209cb6d\"  -h \"x-goog-meta-camera-id:CAM003\"  -h \"x-goog-meta-timestamp:20240815153000\"  -h \"x-goog-meta-latitude:37.7849\"  -h \"x-goog-meta-longitude:-122.4094\"  -h \"x-goog-meta-camera-type:VIRAT_OPENDATA\"  -h \"x-goog-meta-resolution:1920x1080\"  cp \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM003_20240815153000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"gs://homeward_videos_7fde5434/CAM003_20240815153000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\"\n",
      "\n",
      "  Video uploaded successfully with metadata\n",
      "\n",
      "Processing video 4/4: 56f5878c8d777f753209caf2\n",
      "  Filename: CAM004_20240815170000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "  Downloading from: https://data.kitware.com/api/v1/item/56f5878c8d777f753209caf2/download\n",
      "‚úÖ Success: curl -L -f -o \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM004_20240815170000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"https://data.kitware.com/api/v1/item/56f5878c8d777f753209caf2/download\" --connect-timeout 30 --max-time 300\n",
      "  Download completed: 4.8M\n",
      "\n",
      "=== Upload video samples to GCS ===\n",
      "  Uploading video to GCS with metadata...\n",
      "‚úÖ Success: \n",
      "gsutil -h \"Content-Type:video/mp4\"  -h \"x-goog-meta-video-id:56f5878c8d777f753209caf2\"  -h \"x-goog-meta-camera-id:CAM004\"  -h \"x-goog-meta-timestamp:20240815170000\"  -h \"x-goog-meta-latitude:37.7849\"  -h \"x-goog-meta-longitude:-122.4094\"  -h \"x-goog-meta-camera-type:VIRAT_OPENDATA\"  -h \"x-goog-meta-resolution:1920x1080\"  cp \"/var/folders/yb/411wr50n6v1cy6bckcv77d7c0000gn/T/tmptob08dta/CAM004_20240815170000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\" \"gs://homeward_videos_7fde5434/CAM004_20240815170000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\"\n",
      "\n",
      "  Video uploaded successfully with metadata\n",
      "\n",
      "=== Video Processing Summary ===\n",
      "Successfully processed: 4 videos\n",
      "\n",
      "=== Creating BigQuery External Table ===\n",
      "‚úÖ Success: bq mk --table --external_table_definition=\"gs://homeward_videos_7fde5434/*.mp4@us-central1.homeward_gcp_connection\" --object_metadata=SIMPLE \"hackaton-pre-submit:homeward.video_objects\"\n",
      "   Output: Table 'hackaton-pre-submit:homeward.video_objects' successfully created.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"\\n=== Download video samples ===\")\n",
    "\n",
    "# Create temporary directory for downloads\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "print(f\"Using temporary directory: {temp_dir}\")\n",
    "\n",
    "success_count = 0\n",
    "failure_count = 0\n",
    "\n",
    "# Process each video in the VIRAT_VIDEO_SAMPLES\n",
    "for i, video in enumerate(VIRAT_VIDEO_SAMPLES[\"videos\"], 1):\n",
    "    video_id = video[\"id\"]\n",
    "    download_url = video[\"download_url\"]\n",
    "    camera_id = video[\"camera_id\"]\n",
    "    timestamp = video[\"timestamp\"]\n",
    "    latitude = video[\"latitude\"]\n",
    "    longitude = video[\"longitude\"]\n",
    "    camera_type = video[\"camera_type\"]\n",
    "    resolution = video[\"resolution\"]\n",
    "    mime_type = video[\"mime_type\"]\n",
    "\n",
    "    # Generate filename according to Homeward naming convention\n",
    "    filename = f\"{camera_id}_{timestamp}_{latitude}_{longitude}_{camera_type}_{resolution}.mp4\"\n",
    "    temp_file = os.path.join(temp_dir, filename)\n",
    "\n",
    "    print(f\"\\nProcessing video {i}/{len(VIRAT_VIDEO_SAMPLES['videos'])}: {video_id}\")\n",
    "    print(f\"  Filename: {filename}\")\n",
    "    \n",
    "    # Download video file using curl (similar to setup.sh)\n",
    "    print(f\"  Downloading from: {download_url}\")\n",
    "    download_cmd = f'curl -L -f -o \"{temp_file}\" \"{download_url}\" --connect-timeout 30 --max-time 300'\n",
    "\n",
    "    if run_command(download_cmd):\n",
    "        # Get file size for reporting\n",
    "        file_size_cmd = f'du -h \"{temp_file}\"'\n",
    "        try:\n",
    "            result = subprocess.run(file_size_cmd, shell=True, capture_output=True, text=True)\n",
    "            file_size = result.stdout.split()[0] if result.stdout else \"unknown\"\n",
    "            print(f\"  Download completed: {file_size}\")\n",
    "        except:\n",
    "            print(\"  Download completed\")\n",
    "        \n",
    "        print(\"\\n=== Upload video samples to GCS ===\")\n",
    "        # Upload video to GCS with proper content type and custom metadata (similar to setup.sh)\n",
    "        print(\"  Uploading video to GCS with metadata...\") \n",
    "        upload_cmd = f\"\"\"\n",
    "gsutil -h \"Content-Type:{mime_type}\"  \\\n",
    "-h \"x-goog-meta-video-id:{video_id}\"  \\\n",
    "-h \"x-goog-meta-camera-id:{camera_id}\"  \\\n",
    "-h \"x-goog-meta-timestamp:{timestamp}\"  \\\n",
    "-h \"x-goog-meta-latitude:{latitude}\"  \\\n",
    "-h \"x-goog-meta-longitude:{longitude}\"  \\\n",
    "-h \"x-goog-meta-camera-type:{camera_type}\"  \\\n",
    "-h \"x-goog-meta-resolution:{resolution}\"  \\\n",
    "cp \"{temp_file}\" \"gs://{BUCKET_NAME}/{filename}\"\n",
    "\"\"\"\n",
    "\n",
    "        if run_command(upload_cmd):\n",
    "            print(\"  Video uploaded successfully with metadata\")\n",
    "            success_count += 1\n",
    "        else:\n",
    "            print(f\"  Failed to upload video: {filename}\")\n",
    "            failure_count += 1\n",
    "            \n",
    "        # Clean up temporary file\n",
    "        try:\n",
    "            os.remove(temp_file)\n",
    "        except:\n",
    "            pass\n",
    "    else:\n",
    "        print(f\"  Failed to download video: {video_id}\")\n",
    "        failure_count += 1\n",
    "\n",
    "print(\"\\n=== Video Processing Summary ===\")\n",
    "print(f\"Successfully processed: {success_count} videos\")\n",
    "if failure_count > 0:\n",
    "    print(f\"Failed to process: {failure_count} videos\")\n",
    "\n",
    "# Clean up temporary directory\n",
    "try:\n",
    "    os.rmdir(temp_dir)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"\\n=== Creating BigQuery External Table ===\")\n",
    "run_command(f\"bq mk --table --external_table_definition=\\\"gs://{BUCKET_NAME}/*.mp4@{LOCATION}.{CONNECTION_ID}\\\" --object_metadata=SIMPLE \\\"{PROJECT_ID}:{DATASET_ID}.video_objects\\\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "24b3762e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced AI prompt for video analysis using Gemini's multimodal capabilities\n",
    "# This prompt template will be filled with actual missing person data for video search\n",
    "\n",
    "VIDEO_ANALYSIS_PROMPT = \"\"\"# ROLE AND GOAL\n",
    "You are a state-of-the-art AI visual analysis system with an expert specialization in human identification within low-quality video footage.\n",
    "Your primary mission is to analyze the provided video for a critical missing person case with the highest degree of accuracy and diligence.\n",
    "You must be methodical and detail-oriented in your analysis and reporting.\n",
    "\n",
    "# TASK CONTEXT\n",
    "This is a high-priority, time-sensitive analysis.\n",
    "The provided video is a low-quality security footage from the street, where people are walking around.\n",
    "The objective is to determine if the missing person is visible in this video, and if so, to extract all relevant information about their presence.\n",
    "\n",
    "# MISSING PERSON DATA\n",
    "Carefully analyze the following description of the missing person. Every detail is crucial.\n",
    "\n",
    "- **Gender:** `{gender}`\n",
    "- **Approximate Age:** `{age}`\n",
    "- **Build - Height:** `{build_height}`\n",
    "- **Hair Color and Style:** `{hair}`\n",
    "- **Clothing (Top):** `{clothing_top}`\n",
    "- **Clothing (Bottom):** `{clothing_botton}`\n",
    "- **Footwear:** `{footwear}`\n",
    "- **Accessories:** `{accessories}`\n",
    "- **Distinguishing Features:** `{features}`\n",
    "\n",
    "# ANALYSIS INSTRUCTIONS\n",
    "You must perform the following steps in your analysis:\n",
    "\n",
    "1.  **Full Video Scan:** Meticulously review the entire video from start to finish. Do not stop after a potential first match; the person may appear multiple times.\n",
    "2.  **Feature Matching:** Compare every individual in the video against the `MISSING PERSON DATA`. Assess matches based on all available criteria: clothing, build, hair, accessories, and any visible distinguishing features or mannerisms.\n",
    "3.  **Justification:** You MUST provide a step-by-step justification for your match. List the features that matched, the features that did not match, and any features that were ambiguous or obscured (e.g., 'Face was unclear, but clothing is a 90% match').\n",
    "4.  **Contextual Analysis (If Found):** If you identify the person with confidence:\n",
    "    -   Note the exact timestamp(s) (in `HH:MM:SS` format) of their appearance.\n",
    "    -   Describe their actions and behavior (e.g., 'walking quickly', 'talking on the phone', 'sitting on a bench', 'seemed distressed').\n",
    "    -   Analyze if they are with anyone else. If so, provide a detailed description of each companion (gender, estimated age, clothing, etc.).\n",
    "    -   Describe their direction of travel.\n",
    "5. **Confidence Score (If Found):** If you identify a person with confidence:\n",
    "    -   Return the confidence score of the finding in the range 0.0 to 1.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b8b81cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Video analysis prompt configured for missing person search\n",
      "üë§ Target: Male, 35 years old\n",
      "üìè Physical: 1.7m, 80kg\n",
      "üëï Clothing: Red shirt, Blue pants\n",
      "üëü Footwear: White sneakers\n",
      "üï∂Ô∏è Accessories: None\n",
      "üìÜ Date Range: From 2024-08-01 to 2025-06-01\n",
      "üïê Time Range: BETWEEN 11 AND 17\n",
      "üåç Geographic Center: (37.7889, -122.4084)\n",
      "üìç Search Radius: 5.0 km\n"
     ]
    }
   ],
   "source": [
    "# Sample missing person data for video analysis demo\n",
    "# In the web app, this would be dynamically populated from the missing person record\n",
    "sample_video_search_person = {\n",
    "    \"gender\": \"Male\",\n",
    "    \"age\": \"35\",\n",
    "    \"build_height\": \"1.7m, 80kg\",\n",
    "    \"hair\": \"Bald, sporty\",\n",
    "    \"clothing_top\": \"Red shirt\",\n",
    "    \"clothing_botton\": \"Blue pants\",\n",
    "    \"footwear\": \"White sneakers\",\n",
    "    \"accessories\": \"None\",\n",
    "    \"features\": \"None\",\n",
    "}\n",
    "\n",
    "# Video analysis filtering parameters\n",
    "VIDEO_ANALYSIS_BQ_START_DATE = \"2024-08-01\"\n",
    "VIDEO_ANALYSIS_BQ_END_DATE   = \"2025-06-01\"\n",
    "VIDEO_ANALYSIS_BQ_TIME_RANGE = \"BETWEEN 11 AND 17\" \n",
    "\n",
    "# Geographic filtering parameters (Toronto coordinates as example)\n",
    "VIDEO_ANALYSIS_BQ_LATITUDE = \"37.7889\"     # Last seen latitude\n",
    "VIDEO_ANALYSIS_BQ_LONGITUDE = \"-122.4084\"   # Last seen longitude \n",
    "\n",
    "# Test with Toronto\n",
    "#VIDEO_ANALYSIS_BQ_LATITUDE = \"43.6532\"     # Last seen latitude\n",
    "#VIDEO_ANALYSIS_BQ_LONGITUDE = \"-79.3832\"   # Last seen longitude  \n",
    "VIDEO_ANALYSIS_BQ_RADIUS_KM = \"5.0\"        # Search radius in kilometers\n",
    "\n",
    "# Format the video analysis prompt with the sample person data\n",
    "VIDEO_ANALYSIS_PROMPT = VIDEO_ANALYSIS_PROMPT.format(\n",
    "    gender=sample_video_search_person[\"gender\"],\n",
    "    age=sample_video_search_person[\"age\"],\n",
    "    build_height=sample_video_search_person[\"build_height\"],\n",
    "    hair=sample_video_search_person[\"hair\"],\n",
    "    clothing_top=sample_video_search_person[\"clothing_top\"],\n",
    "    clothing_botton=sample_video_search_person[\"clothing_botton\"],\n",
    "    footwear=sample_video_search_person[\"footwear\"],\n",
    "    accessories=sample_video_search_person[\"accessories\"],\n",
    "    features=sample_video_search_person[\"features\"],\n",
    ")\n",
    "\n",
    "print(\"üé¨ Video analysis prompt configured for missing person search\")\n",
    "print(f\"üë§ Target: {sample_video_search_person['gender']}, {sample_video_search_person['age']} years old\")\n",
    "print(f\"üìè Physical: {sample_video_search_person['build_height']}\")\n",
    "print(f\"üëï Clothing: {sample_video_search_person['clothing_top']}, {sample_video_search_person['clothing_botton']}\")\n",
    "print(f\"üëü Footwear: {sample_video_search_person['footwear']}\")\n",
    "print(f\"üï∂Ô∏è Accessories: {sample_video_search_person['accessories']}\")\n",
    "print(f\"üìÜ Date Range: From {VIDEO_ANALYSIS_BQ_START_DATE} to {VIDEO_ANALYSIS_BQ_END_DATE}\")\n",
    "print(f\"üïê Time Range: {VIDEO_ANALYSIS_BQ_TIME_RANGE}\")\n",
    "print(f\"üåç Geographic Center: ({VIDEO_ANALYSIS_BQ_LATITUDE}, {VIDEO_ANALYSIS_BQ_LONGITUDE})\")\n",
    "print(f\"üìç Search Radius: {VIDEO_ANALYSIS_BQ_RADIUS_KM} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "451ce6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      "üé¨ COMPLETE VIDEO ANALYSIS PROMPT FOR GEMINI\n",
      "====================================================================================================\n",
      "# ROLE AND GOAL\n",
      "You are a state-of-the-art AI visual analysis system with an expert specialization in human identification within low-quality video footage.\n",
      "Your primary mission is to analyze the provided video for a critical missing person case with the highest degree of accuracy and diligence.\n",
      "You must be methodical and detail-oriented in your analysis and reporting.\n",
      "\n",
      "# TASK CONTEXT\n",
      "This is a high-priority, time-sensitive analysis.\n",
      "The provided video is a low-quality security footage from the street, where people are walking around.\n",
      "The objective is to determine if the missing person is visible in this video, and if so, to extract all relevant information about their presence.\n",
      "\n",
      "# MISSING PERSON DATA\n",
      "Carefully analyze the following description of the missing person. Every detail is crucial.\n",
      "\n",
      "- **Gender:** `Male`\n",
      "- **Approximate Age:** `35`\n",
      "- **Build - Height:** `1.7m, 80kg`\n",
      "- **Hair Color and Style:** `Bald, sporty`\n",
      "- **Clothing (Top):** `Red shirt`\n",
      "- **Clothing (Bottom):** `Blue pants`\n",
      "- **Footwear:** `White sneakers`\n",
      "- **Accessories:** `None`\n",
      "- **Distinguishing Features:** `None`\n",
      "\n",
      "# ANALYSIS INSTRUCTIONS\n",
      "You must perform the following steps in your analysis:\n",
      "\n",
      "1.  **Full Video Scan:** Meticulously review the entire video from start to finish. Do not stop after a potential first match; the person may appear multiple times.\n",
      "2.  **Feature Matching:** Compare every individual in the video against the `MISSING PERSON DATA`. Assess matches based on all available criteria: clothing, build, hair, accessories, and any visible distinguishing features or mannerisms.\n",
      "3.  **Justification:** You MUST provide a step-by-step justification for your match. List the features that matched, the features that did not match, and any features that were ambiguous or obscured (e.g., 'Face was unclear, but clothing is a 90% match').\n",
      "4.  **Contextual Analysis (If Found):** If you identify the person with confidence:\n",
      "    -   Note the exact timestamp(s) (in `HH:MM:SS` format) of their appearance.\n",
      "    -   Describe their actions and behavior (e.g., 'walking quickly', 'talking on the phone', 'sitting on a bench', 'seemed distressed').\n",
      "    -   Analyze if they are with anyone else. If so, provide a detailed description of each companion (gender, estimated age, clothing, etc.).\n",
      "    -   Describe their direction of travel.\n",
      "5. **Confidence Score (If Found):** If you identify a person with confidence:\n",
      "    -   Return the confidence score of the finding in the range 0.0 to 1.0\n",
      "\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display the complete video analysis prompt for verification\n",
    "# This shows the exact prompt that will be sent to Gemini for video analysis\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"üé¨ COMPLETE VIDEO ANALYSIS PROMPT FOR GEMINI\")\n",
    "print(\"=\" * 100)\n",
    "print(VIDEO_ANALYSIS_PROMPT)\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "565deef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Video analysis BigQuery prepared!\n",
      "üìä Query features:\n",
      "   ‚Ä¢ Processes all videos in {DATASET_ID}.video_objects table\n",
      "   ‚Ä¢ Uses Gemini 2.5 Pro multimodal AI model\n",
      "   ‚Ä¢ Generates secure access URLs for video analysis\n",
      "   ‚Ä¢ Returns structured JSON analysis results\n",
      "   ‚Ä¢ Temperature set to 0 for consistent results\n",
      "   ‚Ä¢ Date and time filtering using metadata fields\n",
      "   ‚Ä¢ Filters by timestamp metadata (format: YYYYMMDDHHMMSS)\n",
      "   ‚Ä¢ Geographic filtering using BigQuery ST_GEOGPOINT/ST_DWITHIN functions\n",
      "   ‚Ä¢ Efficient geospatial filtering with WGS84 ellipsoid accuracy\n",
      "   ‚Ä¢ Current filters: 2024-08-01 to 2025-06-01\n",
      "   ‚Ä¢ Time range: Hours BETWEEN 11 AND 17\n",
      "   ‚Ä¢ Geographic center: (37.7889, -122.4084)\n",
      "   ‚Ä¢ Search radius: 5.0 km\n"
     ]
    }
   ],
   "source": [
    "# BigQuery query to analyze surveillance videos using Gemini 2.5 Pro multimodal model\n",
    "# This query processes videos in the {DATASET_ID}.video_objects table with time and geo filtering to\n",
    "# reduce costs on Gemini API and applies AI analysis to detect the missing person\n",
    "#     output_schema includes the 'result' field due to a problem with AI.GENERATE func\n",
    "\n",
    "VIDEO_ANALYSIS_BQ_QUERY = f\"\"\"\n",
    "SELECT\n",
    "  uri,\n",
    "  AI.GENERATE(\n",
    "    (\n",
    "      \"{{VIDEO_ANALYSIS_PROMPT}}\",\n",
    "      \"\\\\n# RECORDING:  \",\n",
    "      OBJ.GET_ACCESS_URL(ref, 'r')\n",
    "    ),\n",
    "    connection_id => '{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}',\n",
    "    endpoint => 'gemini-2.5-pro',\n",
    "    output_schema => 'personFound BOOL, confidenceScore FLOAT64,summaryOfFindings STRING',\n",
    "    model_params => JSON '{{\"generation_config\": {{\"temperature\": 0}}}}') as result\n",
    "FROM `{DATASET_ID}.video_objects`\n",
    "WHERE 1=1\n",
    "AND EXISTS (\n",
    "  SELECT 1 FROM UNNEST(metadata) AS meta\n",
    "  WHERE meta.name = 'timestamp'\n",
    "  AND PARSE_DATETIME('%Y%m%d%H%M%S', meta.value) BETWEEN\n",
    "  DATETIME('{VIDEO_ANALYSIS_BQ_START_DATE}') AND DATETIME('{VIDEO_ANALYSIS_BQ_END_DATE}')\n",
    ")\n",
    "AND EXISTS (\n",
    "  SELECT 1 FROM UNNEST(metadata) AS meta\n",
    "  WHERE meta.name = 'timestamp'\n",
    "  AND EXTRACT(HOUR FROM PARSE_DATETIME('%Y%m%d%H%M%S', meta.value)) {VIDEO_ANALYSIS_BQ_TIME_RANGE}\n",
    ")\n",
    "AND ST_DWITHIN(\n",
    "  ST_GEOGPOINT(\n",
    "    CAST((SELECT value FROM UNNEST(metadata) WHERE name = 'longitude') AS FLOAT64),\n",
    "    CAST((SELECT value FROM UNNEST(metadata) WHERE name = 'latitude') AS FLOAT64)\n",
    "  ),\n",
    "  ST_GEOGPOINT({VIDEO_ANALYSIS_BQ_LONGITUDE}, {VIDEO_ANALYSIS_BQ_LATITUDE}),\n",
    "  {VIDEO_ANALYSIS_BQ_RADIUS_KM} * 1000  -- Convert km to meters for ST_DWITHIN\n",
    ")\n",
    ";\n",
    "\"\"\".replace(\n",
    "    \"{VIDEO_ANALYSIS_PROMPT}\",\n",
    "    VIDEO_ANALYSIS_PROMPT.encode(\"unicode-escape\")\n",
    "    .replace(b'\"', b'\\\\\"')\n",
    "    .decode(\"utf-8\"),\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_START_DATE}\",\n",
    "    VIDEO_ANALYSIS_BQ_START_DATE\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_END_DATE}\",\n",
    "    VIDEO_ANALYSIS_BQ_END_DATE\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_TIME_RANGE}\",\n",
    "    VIDEO_ANALYSIS_BQ_TIME_RANGE\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_LATITUDE}\",\n",
    "    VIDEO_ANALYSIS_BQ_LATITUDE\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_LONGITUDE}\",\n",
    "    VIDEO_ANALYSIS_BQ_LONGITUDE\n",
    ").replace(\n",
    "    \"{VIDEO_ANALYSIS_BQ_RADIUS_KM}\",\n",
    "    VIDEO_ANALYSIS_BQ_RADIUS_KM\n",
    ")\n",
    "\n",
    "print(\"üîç Video analysis BigQuery prepared!\")\n",
    "print(\"üìä Query features:\")\n",
    "print(\"   ‚Ä¢ Processes all videos in {DATASET_ID}.video_objects table\")\n",
    "print(\"   ‚Ä¢ Uses Gemini 2.5 Pro multimodal AI model\")\n",
    "print(\"   ‚Ä¢ Generates secure access URLs for video analysis\")\n",
    "print(\"   ‚Ä¢ Returns structured JSON analysis results\")\n",
    "print(\"   ‚Ä¢ Temperature set to 0 for consistent results\")\n",
    "print(\"   ‚Ä¢ Date and time filtering using metadata fields\")\n",
    "print(\"   ‚Ä¢ Filters by timestamp metadata (format: YYYYMMDDHHMMSS)\")\n",
    "print(\"   ‚Ä¢ Geographic filtering using BigQuery ST_GEOGPOINT/ST_DWITHIN functions\")\n",
    "print(\"   ‚Ä¢ Efficient geospatial filtering with WGS84 ellipsoid accuracy\")\n",
    "print(f\"   ‚Ä¢ Current filters: {VIDEO_ANALYSIS_BQ_START_DATE} to {VIDEO_ANALYSIS_BQ_END_DATE}\")\n",
    "print(f\"   ‚Ä¢ Time range: Hours {VIDEO_ANALYSIS_BQ_TIME_RANGE}\")\n",
    "print(f\"   ‚Ä¢ Geographic center: ({VIDEO_ANALYSIS_BQ_LATITUDE}, {VIDEO_ANALYSIS_BQ_LONGITUDE})\")\n",
    "print(f\"   ‚Ä¢ Search radius: {VIDEO_ANALYSIS_BQ_RADIUS_KM} km\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f1feaf52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ Executing AI video analysis across all surveillance footage...\n",
      "ü§ñ Using Gemini 2.5 Pro multimodal model for person detection\n",
      "‚úÖ Video analysis completed successfully!\n",
      "üìä Total videos processed: 4\n",
      "üîß Query job ID: dd1cda7f-dba7-423d-82f3-c07c473bb940\n",
      "\n",
      "====================================================================================================\n",
      "üé¨ SURVEILLANCE VIDEO ANALYSIS RESULTS\n",
      "====================================================================================================\n",
      "\n",
      "üé• VIDEO #1\n",
      "------------------------------------------------------------\n",
      "üìÇ URI: gs://homeward_videos_7fde5434/CAM004_20240815170000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "üìπ Camera: CAM004\n",
      "üïê Timestamp: 20240815170000\n",
      "üìç Location: 37.7849_-122.4094\n",
      "\n",
      "ü§ñ AI Analysis Result:\n",
      "‚ùå No person detected\n",
      "üìù Reason: N/A\n",
      "------------------------------------------------------------\n",
      "\n",
      "üé• VIDEO #2\n",
      "------------------------------------------------------------\n",
      "üìÇ URI: gs://homeward_videos_7fde5434/CAM001_20240815123000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "üìπ Camera: CAM001\n",
      "üïê Timestamp: 20240815123000\n",
      "üìç Location: 37.7849_-122.4094\n",
      "\n",
      "ü§ñ AI Analysis Result:\n",
      "‚ùå No person detected\n",
      "üìù Reason: N/A\n",
      "------------------------------------------------------------\n",
      "\n",
      "üé• VIDEO #3\n",
      "------------------------------------------------------------\n",
      "üìÇ URI: gs://homeward_videos_7fde5434/CAM003_20240815153000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "üìπ Camera: CAM003\n",
      "üïê Timestamp: 20240815153000\n",
      "üìç Location: 37.7849_-122.4094\n",
      "\n",
      "ü§ñ AI Analysis Result:\n",
      "üö® PERSON DETECTED!\n",
      "‚≠ê Confidence: 0.6\n",
      "üìù Summary: A potential match was identified between timestamps 00:00 and 00:06. An individual, appearing to be male, is seen on the upper left walkway wearing a red shirt and dark-colored pants, consistent with the missing person's description. The subject walks from right to left before descending the stairs. Due to the significant distance and low resolution, it is impossible to confirm the subject's age, build, hair style (bald), or footwear. The individual appears to be walking alone at a normal pace.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üé• VIDEO #4\n",
      "------------------------------------------------------------\n",
      "üìÇ URI: gs://homeward_videos_7fde5434/CAM002_20240815140000_37.7849_-122.4094_VIRAT_OPENDATA_1920x1080.mp4\n",
      "üìπ Camera: CAM002\n",
      "üïê Timestamp: 20240815140000\n",
      "üìç Location: 37.7849_-122.4094\n",
      "\n",
      "ü§ñ AI Analysis Result:\n",
      "üö® PERSON DETECTED!\n",
      "‚≠ê Confidence: 0.3\n",
      "üìù Summary: A potential match was identified. An individual appears at timestamp 00:13 on the sidewalk in the upper right of the frame and walks from right to left until the end of the footage. Feature Analysis: [Match] The individual is wearing a red top, consistent with the 'Red shirt' description. [Ambiguous] The individual is wearing dark pants, which could be the 'Blue pants' described. [Obscured] Due to the extreme distance and low resolution, it is impossible to verify gender, age, build, hair, or footwear. The person is walking alone at a normal pace. The confidence in this finding is low as it is based solely on a partial clothing match.\n",
      "------------------------------------------------------------\n",
      "\n",
      "üìà ANALYSIS SUMMARY:\n",
      "   üé• Total videos analyzed: 4\n",
      "   ‚úÖ Videos with person detected: 2\n",
      "   ‚ùå Videos without detection: 2\n",
      "   üö® RECOMMEND IMMEDIATE INVESTIGATION OF 2 VIDEO(S)!\n"
     ]
    }
   ],
   "source": [
    "# Execute AI-powered video analysis across all surveillance footage\n",
    "# This processes each video through Gemini 2.5 Pro for missing person detection\n",
    "\n",
    "try:\n",
    "    print(\"üé¨ Executing AI video analysis across all surveillance footage...\")\n",
    "    print(\"ü§ñ Using Gemini 2.5 Pro multimodal model for person detection\")\n",
    "    \n",
    "    # Execute the video analysis query\n",
    "    query_job = client.query(VIDEO_ANALYSIS_BQ_QUERY)\n",
    "    results = query_job.result()\n",
    "    # Collect video URIs where personFound is True\n",
    "    videos_with_persons = []\n",
    "\n",
    "    print(\"‚úÖ Video analysis completed successfully!\")\n",
    "    print(f\"üìä Total videos processed: {results.total_rows}\")\n",
    "    print(f\"üîß Query job ID: {query_job.job_id}\")\n",
    "\n",
    "    if results.total_rows > 0:\n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"üé¨ SURVEILLANCE VIDEO ANALYSIS RESULTS\")\n",
    "        print(\"=\" * 100)\n",
    "        \n",
    "        # Process and display results with enhanced formatting\n",
    "        found_matches = 0\n",
    "        for i, row in enumerate(results, 1):\n",
    "            print(f\"\\nüé• VIDEO #{i}\")\n",
    "            print(\"-\" * 60)\n",
    "            print(f\"üìÇ URI: {row.uri}\")\n",
    "            \n",
    "            # Extract video metadata from filename if available\n",
    "            if row.uri:\n",
    "                filename = row.uri.split('/')[-1]\n",
    "                if '_' in filename:\n",
    "                    parts = filename.split('_')\n",
    "                    if len(parts) >= 4:\n",
    "                        camera_id = parts[0]\n",
    "                        timestamp = parts[1]\n",
    "                        lat_lon = f\"{parts[2]}_{parts[3]}\"\n",
    "                        print(f\"üìπ Camera: {camera_id}\")\n",
    "                        print(f\"üïê Timestamp: {timestamp}\")\n",
    "                        print(f\"üìç Location: {lat_lon}\")\n",
    "            \n",
    "            print(\"\\nü§ñ AI Analysis Result:\")\n",
    "            if row.result:\n",
    "                # Try to parse JSON and format nicely\n",
    "                try:\n",
    "                    analysis = row.result\n",
    "                    if analysis.get('personFound'):\n",
    "                        found_matches += 1\n",
    "                        videos_with_persons.append(row.uri)\n",
    "                        print(\"üö® PERSON DETECTED!\")\n",
    "                        print(f\"‚≠ê Confidence: {analysis.get('confidenceScore', 'N/A')}\")\n",
    "                        print(f\"üìù Summary: {analysis.get('summaryOfFindings', 'N/A')}\")\n",
    "                    else:\n",
    "                        print(\"‚ùå No person detected\")\n",
    "                        print(f\"üìù Reason: {analysis.get('result', 'N/A')}\")\n",
    "                except (Exception):\n",
    "                    print(row.result if row.result else \"No analysis result\")\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è No analysis result returned\")\n",
    "            \n",
    "            print(\"-\" * 60)\n",
    "        \n",
    "        print(\"\\nüìà ANALYSIS SUMMARY:\")\n",
    "        print(f\"   üé• Total videos analyzed: {results.total_rows}\")\n",
    "        print(f\"   ‚úÖ Videos with person detected: {found_matches}\")\n",
    "        print(f\"   ‚ùå Videos without detection: {results.total_rows - found_matches}\")\n",
    "        if found_matches > 0:\n",
    "            print(f\"   üö® RECOMMEND IMMEDIATE INVESTIGATION OF {found_matches} VIDEO(S)!\")\n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No surveillance videos found for analysis\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error executing video analysis: {str(e)}\")\n",
    "    print(f\"üîß Error type: {type(e).__name__}\")\n",
    "    if hasattr(e, \"errors\") and e.errors:\n",
    "        for error in e.errors:\n",
    "            print(f\"üìã Error details: {error}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f999dc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract video URIs with personFound from previous analysis results\n",
    "\n",
    "print(\"üîç EXTRACTING VIDEOS WITH PERSON DETECTIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nüìä Found {len(videos_with_persons)} videos with person detections\")\n",
    "\n",
    "# Download and preview only videos with person detections\n",
    "if len(videos_with_persons) > 0:\n",
    "    temp_folder = tempfile.mkdtemp()\n",
    "\n",
    "    print(f\"\\nüé¨ DOWNLOADING AND PREVIEWING {len(videos_with_persons)} VIDEOS WITH DETECTIONS\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i, video_uri in enumerate(videos_with_persons, 1):\n",
    "        print(f\"\\nüé• Video #{i} with Person Detection:\")\n",
    "        print(f\"üìÇ URI: {video_uri}\")\n",
    "        \n",
    "        # Extract filename from URI\n",
    "        filename = video_uri.split('/')[-1]\n",
    "        local_path = f\"{temp_folder}/{filename}\"\n",
    "        \n",
    "        # Download video using gsutil\n",
    "        print(\"üì• Downloading...\")\n",
    "        download_cmd = f\"gsutil cp '{video_uri}' '{local_path}'\"\n",
    "        \n",
    "        result = os.system(download_cmd)\n",
    "        if result == 0:\n",
    "            print(\"‚úÖ Download successful\")\n",
    "            \n",
    "            # Display video in notebook\n",
    "            print(\"üé¨ Video Preview:\")\n",
    "            display(Video(local_path, width=800, height=450))\n",
    "            \n",
    "        else:\n",
    "            print(\"‚ùå Download failed\")\n",
    "            \n",
    "else:\n",
    "    print(\"\\nüìπ No videos with person detections found.\")\n",
    "    print(\"üí° Note: When videos with personFound=True are available, they will be automatically downloaded and previewed here.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2b26ec",
   "metadata": {},
   "source": [
    "---\n",
    "# üßπ Environment Cleanup\n",
    "\n",
    "This section provides cleanup functionality to remove all GCP resources created during this demo. This is equivalent to running the `destroy.sh` script but adapted for the notebook environment.\n",
    "\n",
    "‚ö†Ô∏è **WARNING**: This will permanently delete all resources including:\n",
    "- Storage bucket and all uploaded videos\n",
    "- BigQuery dataset and all tables\n",
    "- BigQuery connection and associated service accounts\n",
    "\n",
    "**Uncomment and run the cells below only when you want to completely clean up the environment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c4d243d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleting BigQuery dataset...\n",
      "‚úÖ Success: bq rm -r -f --project_id={PROJECT_ID} {DATASET_ID}\n",
      "‚úÖ BigQuery dataset deleted: {DATASET_ID}\n",
      "üí° Cleanup commands are commented out for safety. Uncomment to execute.\n"
     ]
    }
   ],
   "source": [
    "# # DELETE BIGQUERY DATASET\n",
    "# print(\"üóëÔ∏è Deleting BigQuery dataset...\")\n",
    "# if run_command(f\"bq rm -r -f --project_id={PROJECT_ID} {DATASET_ID}\"):\n",
    "#     print(f\"‚úÖ BigQuery dataset deleted: {DATASET_ID}\")\n",
    "# else :\n",
    "#     print(\"‚ö†Ô∏è Dataset may not exist or already deleted\")\n",
    "\n",
    "# print(\"üí° Cleanup commands are commented out for safety. Uncomment to execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26eb6b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleting BigQuery connection...\n",
      "‚úÖ Success: bq rm --connection --location={LOCATION} --project_id={PROJECT_ID} {CONNECTION_ID}\n",
      "‚úÖ BigQuery connection deleted: {CONNECTION_ID}\n",
      "üí° Connection cleanup commands are commented out for safety. Uncomment to execute.\n"
     ]
    }
   ],
   "source": [
    "# DELETE BIGQUERY CONNECTION AND IAM BINDINGS\n",
    "# print(\"üóëÔ∏è Deleting BigQuery connection...\")\n",
    "# try:\n",
    "#     connection_full_id = f\"{PROJECT_ID}.{LOCATION}.{CONNECTION_ID}\"\n",
    "    \n",
    "#     # Delete the connection\n",
    "#     run_command(f\"bq rm --connection --location={LOCATION} --project_id={PROJECT_ID} {CONNECTION_ID}\")\n",
    "#     print(f\"‚úÖ BigQuery connection deleted: {CONNECTION_ID}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Connection may not exist or already deleted: {e}\")\n",
    "\n",
    "print(\"üí° Connection cleanup commands are commented out for safety. Uncomment to execute.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c6a94d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üóëÔ∏è Deleting storage bucket and all contents...\n",
      "‚úÖ Success: gsutil ls -b gs://{DATASET_ID}_videos_c175266e\n",
      "   Output: gs://{DATASET_ID}_videos_c175266e/\n",
      "‚úÖ Success: gsutil -m rm gs://{DATASET_ID}_videos_c175266e/**\n",
      "‚úÖ Success: gsutil rb gs://{DATASET_ID}_videos_c175266e\n",
      "‚úÖ Storage bucket deleted: gs://{DATASET_ID}_videos_c175266e\n",
      "üí° Storage cleanup commands are commented out for safety. Uncomment to execute.\n"
     ]
    }
   ],
   "source": [
    "# DELETE STORAGE BUCKET AND ALL CONTENTS\n",
    "# print(\"üóëÔ∏è Deleting storage bucket and all contents...\")\n",
    "# try:\n",
    "#     # Check if bucket exists\n",
    "#     bucket_exists = run_command(f\"gsutil ls -b gs://{BUCKET_NAME}\")\n",
    "#     if bucket_exists is not None:  \n",
    "#         run_command(f\"gsutil -m rm gs://{BUCKET_NAME}/**\")\n",
    "#         # Delete the bucket itself\n",
    "#         run_command(f\"gsutil rb gs://{BUCKET_NAME}\")\n",
    "#         print(f\"‚úÖ Storage bucket deleted: gs://{BUCKET_NAME}\")\n",
    "#     else:\n",
    "#         print(f\"‚ö†Ô∏è Bucket does not exist: gs://{BUCKET_NAME}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"‚ö†Ô∏è Bucket may not exist or already deleted: {e}\")\n",
    "\n",
    "print(\"üí° Storage cleanup commands are commented out for safety. Uncomment to execute.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
